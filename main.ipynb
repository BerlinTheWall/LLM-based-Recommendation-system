{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from CF_SVD import SVD_CF\n",
    "from CF_item_based import ItemBasedCF\n",
    "from CF_user_based import UserBasedCF\n",
    "from TwoTowerModel import TwoTowerModel\n",
    "from dataset_processor import DatasetProcessor\n",
    "from dataset_statistics import DatasetStatistics\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-30T16:14:15.500497Z",
     "end_time": "2024-07-30T16:14:21.732180Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# movielens_data = pd.read_csv('processed_dataset/MovieLens-1M/ratings/fulldata_movielens.csv')\n",
    "# train_ratings = pd.read_csv('processed_dataset/MovieLens-1M/ratings/traindata_movielens.csv')\n",
    "# test_ratings = pd.read_csv('processed_dataset/MovieLens-1M/ratings/testdata_movielens.csv')\n",
    "\n",
    "train_ratings = pd.read_csv('processed_dataset/MovieLens-1M/ratings/ratings_traindata_movielens.csv')\n",
    "test_ratings = pd.read_csv('processed_dataset/MovieLens-1M/ratings/ratings_testdata_movielens.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-27T12:57:37.674280Z",
     "end_time": "2024-07-27T12:57:37.864277Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse User-Item matrix: (6040, 3667)\n",
      "Shape of Sparse User Similarity matrix: (6040, 6040)\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "\n",
    "user_cf = UserBasedCF(train_ratings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-27T12:57:37.866276Z",
     "end_time": "2024-07-27T12:57:40.109638Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# recommendations_movielens = cf.generate_recommendations(test_ratings, k)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-27T12:57:40.921513Z",
     "end_time": "2024-07-27T12:57:40.940660Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_recommendations(self, user_id, k):\n",
    "    if user_id not in self.user_similarity_df.index:\n",
    "        return pd.Series()\n",
    "\n",
    "    # Get the similarity scores for the user and filter out users with similarity <= 0\n",
    "    similar_users = self.user_similarity_df[user_id][self.user_similarity_df[user_id] > 0].sort_values(\n",
    "        ascending=False)\n",
    "\n",
    "    if similar_users.empty:\n",
    "        return pd.Series()  # Return an empty series if no similar users with similarity > 0\n",
    "\n",
    "    # Get indices of similar users\n",
    "    similar_users_indices = similar_users.index\n",
    "\n",
    "    # Create a sparse matrix of user ratings filtered by similar users\n",
    "    user_ratings_sparse = self.user_item_matrix.loc[similar_users_indices].to_numpy()\n",
    "    user_similarities = similar_users.to_numpy()\n",
    "\n",
    "    # Calculate weighted ratings\n",
    "    weighted_ratings = user_ratings_sparse.T.dot(user_similarities) / user_similarities.sum()\n",
    "\n",
    "    # Normalize weighted ratings to be between 1 and 5\n",
    "    min_rating = 1\n",
    "    max_rating = 5\n",
    "    weighted_ratings = min_rating + (max_rating - min_rating) * (weighted_ratings - weighted_ratings.min()) / (\n",
    "            weighted_ratings.max() - weighted_ratings.min())\n",
    "\n",
    "    # Convert the weighted ratings back to a Series with item IDs as index\n",
    "    weighted_ratings_series = pd.Series(weighted_ratings, index=self.user_item_matrix.columns)\n",
    "\n",
    "    # Exclude items the user has already rated\n",
    "    already_rated = self.user_item_matrix.loc[user_id][self.user_item_matrix.loc[user_id] > 0].index\n",
    "    recommendations = weighted_ratings_series.drop(already_rated).sort_values(ascending=False).head(k)\n",
    "\n",
    "    return recommendations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def dcg_at_k(y_true_sorted, k):\n",
    "    y_true_sorted = np.asarray(y_true_sorted)[:k]\n",
    "    return np.sum((2**y_true_sorted - 1) / np.log2(np.arange(2, len(y_true_sorted) + 2)))\n",
    "\n",
    "def ndcg_at_k(y_true, y_score, k):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true_sorted = np.take(y_true, order[:k])\n",
    "    dcg = dcg_at_k(y_true_sorted, k)\n",
    "    idcg = dcg_at_k(sorted(y_true, reverse=True), k)\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "def recall_at_k(y_true, y_score, k):\n",
    "    top_k_items = np.argsort(y_score)[::-1][:k]\n",
    "    hits = np.sum(y_true[top_k_items])\n",
    "    return hits / np.sum(y_true)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-27T12:57:48.183540Z",
     "end_time": "2024-07-27T12:57:48.214852Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n",
      "C:\\Users\\Hooman\\AppData\\Local\\Temp\\ipykernel_32936\\4188945968.py:17: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return hits / np.sum(y_true)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NDCG@5': 0.863445572289752, 'Recall@5': nan}\n"
     ]
    }
   ],
   "source": [
    "def evaluate_user_based_cf_model(model, test_data, k):\n",
    "    ndcg_scores = []\n",
    "    recall_scores = []\n",
    "\n",
    "    # Get unique users\n",
    "    unique_users = test_data['user_id'].unique()\n",
    "\n",
    "    for user in unique_users:\n",
    "        # Get items and labels for the user\n",
    "        user_data = test_data[test_data['user_id'] == user]\n",
    "        item_ids = user_data['item_id'].values\n",
    "        labels = user_data['rating'].values\n",
    "\n",
    "        # Get recommendations for the user\n",
    "        recommendations = model.get_recommendations(user, k)\n",
    "\n",
    "        if recommendations.empty:\n",
    "            continue\n",
    "\n",
    "        # Create a score array where recommended items have a high score\n",
    "        scores = np.zeros_like(item_ids, dtype=float)\n",
    "        for i, item_id in enumerate(item_ids):\n",
    "            if item_id in recommendations.index:\n",
    "                scores[i] = recommendations[item_id]\n",
    "\n",
    "        # Calculate NDCG and Recall\n",
    "        ndcg = ndcg_at_k(labels, scores, k)\n",
    "        recall = recall_at_k(labels, scores, k)\n",
    "\n",
    "        ndcg_scores.append(ndcg)\n",
    "        recall_scores.append(recall)\n",
    "\n",
    "    avg_ndcg = np.mean(ndcg_scores)\n",
    "    avg_recall = np.mean(recall_scores)\n",
    "\n",
    "    return {\n",
    "        'NDCG@{}'.format(k): avg_ndcg,\n",
    "        'Recall@{}'.format(k): avg_recall\n",
    "    }\n",
    "\n",
    "# Evaluate the model\n",
    "eval_result = evaluate_user_based_cf_model(user_cf, test_ratings, k=5)\n",
    "print(eval_result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-27T12:58:03.383085Z",
     "end_time": "2024-07-27T15:00:34.616536Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "102759"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ratings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-27T15:00:34.618523Z",
     "end_time": "2024-07-27T15:00:34.661580Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "# import numpy as np\n",
    "\n",
    "# Prepare test data for NDCG calculation\n",
    "test_ratings['predicted_rating'] = test_ratings.apply(lambda row: recommendations_movielens.get(row['user_id'], pd.Series()).get(row['item_id'], 0), axis=1)\n",
    "test_ratings_grouped = test_ratings.groupby('user_id')\n",
    "\n",
    "# ndcg_scores = []\n",
    "#\n",
    "# for user, group in test_ratings_grouped:\n",
    "#     true_ratings = group['rating'].values\n",
    "#     pred_ratings = group['predicted_rating'].values\n",
    "#     ndcg_scores.append(ndcg_score([true_ratings], [pred_ratings], k=10))\n",
    "#\n",
    "# user_cf_ndcg = np.mean(ndcg_scores)\n",
    "# print(\"User-Based CF NDCG:\", user_cf_ndcg)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-20T20:07:15.241961Z",
     "end_time": "2024-07-20T20:07:27.039126Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ndcg_scores = []\n",
    "\n",
    "for user, group in test_ratings_grouped:\n",
    "    if len(group) > 1:  # Filter users with more than one rating\n",
    "        true_ratings = group['rating'].values\n",
    "        pred_ratings = group['predicted_rating'].values\n",
    "        ndcg_scores.append(ndcg_score([true_ratings], [pred_ratings], k=5))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-20T20:07:36.210085Z",
     "end_time": "2024-07-20T20:07:39.871041Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user_cf_ndcg = np.mean(ndcg_scores)\n",
    "print(\"User-Based CF NDCG:\", user_cf_ndcg)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "baliee jadide"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-Based CF NDCG: 0.8280448809270077\n"
     ]
    }
   ],
   "source": [
    "user_cf_ndcg = np.mean(ndcg_scores)\n",
    "print(\"User-Based CF NDCG:\", user_cf_ndcg)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-20T20:07:39.871041Z",
     "end_time": "2024-07-20T20:07:39.886176Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model.to('cuda')  # Ensure the model is on the correct device\n",
    "\n",
    "# Initialize the metric evaluator\n",
    "metric_evaluator = Metric(k=[5, 10, 20])\n",
    "\n",
    "# Evaluate the model\n",
    "eval_result = metric_evaluator.eval(model, test_dataloader, topks=[5, 10, 20])\n",
    "\n",
    "# Print the results\n",
    "for metric, values in eval_result.items():\n",
    "    print(f\"{metric}: {values}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "        user_id  item_id  rating   timestamp  predicted_rating\n0          6040     2384       4   956703954          0.000000\n1          6040      573       4   956704056          0.000000\n2          6040     1734       2   956704081          0.000000\n3          6040      912       5   956704191          0.000000\n4          6040     2028       5   956704519          1.361253\n...         ...      ...     ...         ...               ...\n200037      424     2581       3  1046349099          0.000000\n200038     5950     3654       3  1046368480          0.000000\n200039     5950     3328       3  1046369090          0.000000\n200040     5950     3481       4  1046369090          0.000000\n200041     4958     3489       4  1046454320          0.000000\n\n[200042 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>rating</th>\n      <th>timestamp</th>\n      <th>predicted_rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6040</td>\n      <td>2384</td>\n      <td>4</td>\n      <td>956703954</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6040</td>\n      <td>573</td>\n      <td>4</td>\n      <td>956704056</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6040</td>\n      <td>1734</td>\n      <td>2</td>\n      <td>956704081</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6040</td>\n      <td>912</td>\n      <td>5</td>\n      <td>956704191</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6040</td>\n      <td>2028</td>\n      <td>5</td>\n      <td>956704519</td>\n      <td>1.361253</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>200037</th>\n      <td>424</td>\n      <td>2581</td>\n      <td>3</td>\n      <td>1046349099</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>200038</th>\n      <td>5950</td>\n      <td>3654</td>\n      <td>3</td>\n      <td>1046368480</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>200039</th>\n      <td>5950</td>\n      <td>3328</td>\n      <td>3</td>\n      <td>1046369090</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>200040</th>\n      <td>5950</td>\n      <td>3481</td>\n      <td>4</td>\n      <td>1046369090</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>200041</th>\n      <td>4958</td>\n      <td>3489</td>\n      <td>4</td>\n      <td>1046454320</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>200042 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ratings"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-20T20:07:44.885420Z",
     "end_time": "2024-07-20T20:07:44.932198Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@5: 0.7092\n",
      "MRR@5: 0.6328\n",
      "HR@5: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from evaluator import EvaluateMetrics\n",
    "\n",
    "evaluator = EvaluateMetrics(movielens_testset)\n",
    "results = evaluator.evaluate_recommendations(recommendations_movielens, k)\n",
    "print(f\"NDCG@{k}: {results['NDCG@k']:.4f}\")\n",
    "print(f\"MRR@{k}: {results['MRR@k']:.4f}\")\n",
    "print(f\"HR@{k}: {results['HR@k']:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-20T13:48:12.938896Z",
     "end_time": "2024-07-20T13:48:38.102934Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@5: 0.4126\n",
      "MRR@5: 0.3682\n",
      "HR@5: 0.5818\n"
     ]
    }
   ],
   "source": [
    "from evaluator import EvaluateMetrics\n",
    "\n",
    "evaluator = EvaluateMetrics(movielens_testset)\n",
    "results = evaluator.evaluate_recommendation_without_history(recommendations_movielens, k)\n",
    "print(f\"NDCG@{k}: {results['NDCG@k']:.4f}\")\n",
    "print(f\"MRR@{k}: {results['MRR@k']:.4f}\")\n",
    "print(f\"HR@{k}: {results['HR@k']:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-20T13:52:28.023132Z",
     "end_time": "2024-07-20T13:52:31.882191Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from CF_SVD import SVD_CF\n",
    "from CF_item_based import ItemBasedCF\n",
    "from CF_user_based import UserBasedCF\n",
    "from TwoTowerModel import TwoTowerModel\n",
    "from dataset_processor import DatasetProcessor\n",
    "from dataset_statistics import DatasetStatistics\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-24T19:05:25.497179Z",
     "end_time": "2024-07-24T19:05:34.437206Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "fields = ['rating', 'user_id', 'item_id', 'timestamp']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-24T19:11:21.782383Z",
     "end_time": "2024-07-24T19:11:21.817894Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "dat_file_path = 'datasets/ml-1m/ml-1m/ratings.dat'\n",
    "processor_dat = DatasetProcessor(dat_file_path, fields, 'movielens')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-24T19:11:22.137361Z",
     "end_time": "2024-07-24T19:11:22.150356Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sorted by 'timestamp' in ascending order.\n"
     ]
    }
   ],
   "source": [
    "processor_dat.load_data()\n",
    "processor_dat.sort_by_column(column_name=\"timestamp\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-24T19:11:22.494272Z",
     "end_time": "2024-07-24T19:11:27.937371Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info of the dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1000209 entries, 1000138 to 825603\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count    Dtype\n",
      "---  ------     --------------    -----\n",
      " 0   user_id    1000209 non-null  int64\n",
      " 1   item_id    1000209 non-null  int64\n",
      " 2   rating     1000209 non-null  int64\n",
      " 3   timestamp  1000209 non-null  int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 38.2 MB\n"
     ]
    }
   ],
   "source": [
    "stats = DatasetStatistics(processor_dat.data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-24T19:11:27.940371Z",
     "end_time": "2024-07-24T19:11:28.012240Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated ratings:\n",
      "Empty DataFrame\n",
      "Columns: [user_id, item_id, rating, timestamp]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "stats.show_duplicates()\n",
    "stats.drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-24T19:11:27.968727Z",
     "end_time": "2024-07-24T19:11:28.215589Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# unique USERS who have rated 5 or more products : 6040\n",
      "# unique USERS dropped      : 0\n",
      "# unique ITEMS remaining    : 3706\n",
      "# unique ITEMS dropped      : 0\n",
      "\n",
      "Final length of the dataset : 1000209\n"
     ]
    }
   ],
   "source": [
    "processor_dat.filter_data(min_ratings=5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-24T19:11:28.188531Z",
     "end_time": "2024-07-24T19:11:28.281598Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings binarized with threshold 3.\n"
     ]
    }
   ],
   "source": [
    "processor_dat.binarize_ratings(threshold=3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-24T19:11:28.285615Z",
     "end_time": "2024-07-24T19:11:28.598216Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full data set saved to: .\\rating_fulldata_movielens.csv\n",
      "Train set saved to: .\\rating_traindata_movielens.csv\n",
      "Validation set saved to: .\\rating_valdata_movielens.csv\n",
      "Test set saved to: .\\rating_testdata_movielens.csv\n"
     ]
    }
   ],
   "source": [
    "processor_dat.split_data()\n",
    "processor_dat.save_data(output_dir='.', prefix='rating')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-24T19:13:18.526249Z",
     "end_time": "2024-07-24T19:13:32.031954Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('rating_traindata_movielens.csv')\n",
    "val_df = pd.read_csv('rating_valdata_movielens.csv')\n",
    "test_df = pd.read_csv('rating_testdata_movielens.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-24T19:18:20.291479Z",
     "end_time": "2024-07-24T19:18:20.614156Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      user_id  total_count  train_count  val_count  test_count  \\\n",
      "0           1           53           42          5           6   \n",
      "1           2          129          103         13          13   \n",
      "2           3           51           40          5           6   \n",
      "3           4           21           16          2           3   \n",
      "4           5          198          158         20          20   \n",
      "...       ...          ...          ...        ...         ...   \n",
      "6035     6036          888          710         89          89   \n",
      "6036     6037          202          161         20          21   \n",
      "6037     6038           20           16          2           2   \n",
      "6038     6039          123           98         12          13   \n",
      "6039     6040          341          272         34          35   \n",
      "\n",
      "      train_percentage  val_percentage  test_percentage  \n",
      "0             0.792453        0.094340         0.113208  \n",
      "1             0.798450        0.100775         0.100775  \n",
      "2             0.784314        0.098039         0.117647  \n",
      "3             0.761905        0.095238         0.142857  \n",
      "4             0.797980        0.101010         0.101010  \n",
      "...                ...             ...              ...  \n",
      "6035          0.799550        0.100225         0.100225  \n",
      "6036          0.797030        0.099010         0.103960  \n",
      "6037          0.800000        0.100000         0.100000  \n",
      "6038          0.796748        0.097561         0.105691  \n",
      "6039          0.797654        0.099707         0.102639  \n",
      "\n",
      "[6040 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all datasets to calculate the total counts per user\n",
    "all_data = pd.concat([train_df, val_df, test_df])\n",
    "\n",
    "# Calculate the total count of records for each user in the entire dataset\n",
    "total_counts = all_data.groupby('user_id').size().reset_index(name='total_count')\n",
    "\n",
    "# Calculate the count of records for each user in the train set\n",
    "train_counts = train_df.groupby('user_id').size().reset_index(name='train_count')\n",
    "\n",
    "# Calculate the count of records for each user in the validation set\n",
    "val_counts = val_df.groupby('user_id').size().reset_index(name='val_count')\n",
    "\n",
    "# Calculate the count of records for each user in the test set\n",
    "test_counts = test_df.groupby('user_id').size().reset_index(name='test_count')\n",
    "\n",
    "# Merge all counts into a single DataFrame\n",
    "merged_counts = total_counts.merge(train_counts, on='user_id', how='left').merge(val_counts, on='user_id', how='left').merge(test_counts, on='user_id', how='left')\n",
    "\n",
    "# Fill NaN values with 0 (in case a user doesn't appear in a specific set)\n",
    "merged_counts.fillna(0, inplace=True)\n",
    "\n",
    "# Calculate the percentage for each set\n",
    "merged_counts['train_percentage'] = merged_counts['train_count'] / merged_counts['total_count']\n",
    "merged_counts['val_percentage'] = merged_counts['val_count'] / merged_counts['total_count']\n",
    "merged_counts['test_percentage'] = merged_counts['test_count'] / merged_counts['total_count']\n",
    "\n",
    "# Check the distribution\n",
    "print(merged_counts)\n",
    "\n",
    "# Optionally, you can save the results to a CSV file\n",
    "merged_counts.to_csv('user_distribution_check.csv', index=False)\n",
    "\n",
    "# Display any users who do not follow the 80-10-10 distribution (within a tolerance)\n",
    "tolerance = 0.05\n",
    "incorrect_distribution = merged_counts[\n",
    "    (abs(merged_counts['train_percentage'] - 0.8) > tolerance) |\n",
    "    (abs(merged_counts['val_percentage'] - 0.1) > tolerance) |\n",
    "    (abs(merged_counts['test_percentage'] - 0.1) > tolerance)\n",
    "]\n",
    "\n",
    "# print(\"Users with incorrect distribution:\")\n",
    "# print(incorrect_distribution)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-24T18:32:16.031351Z",
     "end_time": "2024-07-24T18:32:16.193374Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "       user_id  item_id  rating  timestamp\n0            1      745       3  978824268\n1            1      595       5  978824268\n2            1      588       4  978824268\n3            1        1       5  978824268\n4            1     2687       3  978824268\n...        ...      ...     ...        ...\n99687     6040     3083       4  963272132\n99688     6040     2366       3  963272166\n99689     6040     3819       5  963272166\n99690     6040     1900       5  964828352\n99691     6040     1188       4  964828503\n\n[99692 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>745</td>\n      <td>3</td>\n      <td>978824268</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>595</td>\n      <td>5</td>\n      <td>978824268</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>588</td>\n      <td>4</td>\n      <td>978824268</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>978824268</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>2687</td>\n      <td>3</td>\n      <td>978824268</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>99687</th>\n      <td>6040</td>\n      <td>3083</td>\n      <td>4</td>\n      <td>963272132</td>\n    </tr>\n    <tr>\n      <th>99688</th>\n      <td>6040</td>\n      <td>2366</td>\n      <td>3</td>\n      <td>963272166</td>\n    </tr>\n    <tr>\n      <th>99689</th>\n      <td>6040</td>\n      <td>3819</td>\n      <td>5</td>\n      <td>963272166</td>\n    </tr>\n    <tr>\n      <th>99690</th>\n      <td>6040</td>\n      <td>1900</td>\n      <td>5</td>\n      <td>964828352</td>\n    </tr>\n    <tr>\n      <th>99691</th>\n      <td>6040</td>\n      <td>1188</td>\n      <td>4</td>\n      <td>964828503</td>\n    </tr>\n  </tbody>\n</table>\n<p>99692 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-24T18:32:16.155378Z",
     "end_time": "2024-07-24T18:32:16.193374Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def dcg(scores, k):\n",
    "    \"\"\"\n",
    "    Compute Discounted Cumulative Gain (DCG) for the top-k results.\n",
    "\n",
    "    :param scores: List of relevance scores.\n",
    "    :param k: Number of top results to consider.\n",
    "    :return: DCG value.\n",
    "    \"\"\"\n",
    "    scores = np.asfarray(scores)[:k]\n",
    "    return np.sum(scores / np.log2(np.arange(2, scores.size + 2)))\n",
    "\n",
    "def ndcg(scores, k):\n",
    "    \"\"\"\n",
    "    Compute Normalized Discounted Cumulative Gain (NDCG) for the top-k results.\n",
    "\n",
    "    :param scores: List of relevance scores.\n",
    "    :param k: Number of top results to consider.\n",
    "    :return: NDCG value.\n",
    "    \"\"\"\n",
    "    ideal_scores = sorted(scores, reverse=True)\n",
    "    return dcg(scores, k) / dcg(ideal_scores, k)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-27T18:12:27.057309Z",
     "end_time": "2024-07-27T18:12:27.081234Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@5: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Given relevance scores\n",
    "relevance_scores = [1, 0, 0, 0, 0]\n",
    "k = len(relevance_scores)\n",
    "ndcg_value = ndcg(relevance_scores, k)\n",
    "\n",
    "print(f\"NDCG@{k}: {ndcg_value}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-27T18:12:54.208308Z",
     "end_time": "2024-07-27T18:12:54.227743Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test_data = pd.DataFrame({\n",
    "    'user': [1, 1, 1, 2, 2],\n",
    "    'item': [101, 102, 103, 201, 202],\n",
    "    'label': [1, 0, 1, 1, 0]\n",
    "})\n",
    "all_items = np.array([100, 101, 102, 103, 104, 200, 201, 202])\n",
    "recommended_items = {\n",
    "    1: [101, 102, 104, 103, 105],  # Items recommended for user 1\n",
    "    2: [201, 202, 200, 203, 204]   # Items recommended for user 2\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-30T16:14:30.513711Z",
     "end_time": "2024-07-30T16:14:30.533232Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_score for user 1: [3, 4, 2.5, 5, 2.5]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "test_data = pd.DataFrame({\n",
    "    'user': [1, 1, 1, 2, 2],\n",
    "    'item': [101, 102, 103, 201, 202],\n",
    "    'label': [3, 4, 5, 1, 2]\n",
    "})\n",
    "\n",
    "all_items = np.array([100, 101, 102, 103, 104, 200, 201, 202])\n",
    "\n",
    "recommended_items = {\n",
    "    1: [101, 102, 104, 103, 105],  # Items recommended for user 1\n",
    "}\n",
    "\n",
    "# User 1 example\n",
    "user = 1\n",
    "user_test_data = test_data[test_data['user'] == user]\n",
    "test_items = user_test_data['item'].values\n",
    "labels = user_test_data['label'].values\n",
    "\n",
    "recommended_items_user = recommended_items[user]\n",
    "\n",
    "y_score = [\n",
    "    user_test_data[user_test_data['item'] == item]['label'].values[0] if item in test_items else 2.5\n",
    "    for item in recommended_items_user\n",
    "]\n",
    "\n",
    "print(\"y_score for user 1:\", y_score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-30T16:36:18.615438Z",
     "end_time": "2024-07-30T16:36:18.624438Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2000, 0.5000, 0.3000, 0.7000, 0.1000]]) tensor([[0, 1, 0, 0, 0]])\n",
      "tensor([[3, 1, 2, 0, 4]])\n",
      "tensor([[0, 1, 0, 0, 0]])\n",
      "tensor([2, 3, 4, 5, 6])\n",
      "tensor([1.0000, 0.6309, 0.5000, 0.4307, 0.3869])\n",
      "NDCG@5: 0.6309297680854797\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define the ndcg function\n",
    "def ndcg(scores, labels, k):\n",
    "    scores = scores.cpu()\n",
    "    labels = labels.cpu()\n",
    "    print(scores, labels)\n",
    "    rank = (-scores).argsort(dim=1)\n",
    "    print(rank)\n",
    "    cut = rank[:, :k]\n",
    "    hits = labels.gather(1, cut)\n",
    "    print(hits)\n",
    "    position = torch.arange(2, 2+k)\n",
    "    print(position)\n",
    "    weights = 1 / torch.log2(position.float())\n",
    "    print(weights)\n",
    "    dcg = (hits.float() * weights).sum(1)\n",
    "    idcg = torch.Tensor([weights[:min(int(n), k)].sum() for n in labels.sum(1)])\n",
    "    ndcg = dcg / idcg\n",
    "    return ndcg.mean()\n",
    "\n",
    "# Example usage:\n",
    "# Predicted scores for 3 samples (each with 5 items)\n",
    "scores = torch.tensor([[0.2, 0.5, 0.3, 0.7, 0.1]])\n",
    "\n",
    "# Corresponding labels (1 indicates relevant, 0 indicates not relevant)\n",
    "labels = torch.tensor([[0, 1, 0, 0, 0]])\n",
    "\n",
    "# Calculate NDCG for top 3 items\n",
    "k = 5\n",
    "ndcg_value = ndcg(scores, labels, k)\n",
    "print(f\"NDCG@{k}: {ndcg_value.item()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-31T21:45:04.194112Z",
     "end_time": "2024-07-31T21:45:04.217144Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
