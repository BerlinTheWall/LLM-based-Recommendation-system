{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "D:\\Anaconda\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Load the pre-trained SBERT model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-07T17:18:13.609124Z",
     "end_time": "2024-08-07T17:18:35.748644Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity with sentence 1: 0.05875241011381149\n",
      "Similarity with sentence 2: 0.05363810807466507\n",
      "Similarity with sentence 3: 0.049956221133470535\n",
      "Similarity with sentence 4: 0.08661812543869019\n"
     ]
    }
   ],
   "source": [
    "# Define your sentences\n",
    "sentence1 = \"occupation: doctor/health care [SEP] age: 25-34 [SEP] gender: Male\"\n",
    "sentence2_list = [\n",
    "    \"title: Godfather, The [SEP] genres: Action, Crime, Drama [SEP] year: 1934\",\n",
    "    \"title: Godfather, The [SEP] genres: Action|Crime|Drama [SEP] year: 1934\",\n",
    "    \"title: Godfather, The [SEP] genres: Action, Crime, Drama\",\n",
    "    \"genres: Action, Crime, Drama\",\n",
    "]\n",
    "\n",
    "# Compute the embedding for the first sentence\n",
    "embedding1 = model.encode(sentence1, convert_to_tensor=True)\n",
    "\n",
    "# Compute the embeddings for the list of sentences\n",
    "embeddings2 = model.encode(sentence2_list, convert_to_tensor=True)\n",
    "\n",
    "# Compute the cosine similarity between the first sentence and each sentence in the list\n",
    "similarities = util.pytorch_cos_sim(embedding1, embeddings2)\n",
    "\n",
    "# Print the similarity scores\n",
    "for i, similarity in enumerate(similarities[0]):\n",
    "    print(f\"Similarity with sentence {i+1}: {similarity.item()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-07T11:55:47.729354Z",
     "end_time": "2024-08-07T11:55:47.807388Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity with sentence 1: 0.07378441840410233\n",
      "Similarity with sentence 2: 0.07856899499893188\n",
      "Similarity with sentence 3: 0.09538991004228592\n",
      "Similarity with sentence 4: 0.14021624624729156\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define your sentences\n",
    "sentence1 = \"occupation: doctor/health care [SEP] gender: Male\"\n",
    "sentence2_list = [\n",
    "    \"title: Godfather, The [SEP] genres: Action, Crime, Drama [SEP] year: 1934\",\n",
    "    \"title: Godfather, The [SEP] genres: Action|Crime|Drama [SEP] year: 1934\",\n",
    "    \"title: Godfather, The [SEP] genres: Action, Crime, Drama\",\n",
    "    \"genres: Action, Crime, Drama\",\n",
    "]\n",
    "\n",
    "# Compute the embedding for the first sentence\n",
    "embedding1 = model.encode(sentence1, convert_to_tensor=True)\n",
    "\n",
    "# Compute the embeddings for the list of sentences\n",
    "embeddings2 = model.encode(sentence2_list, convert_to_tensor=True)\n",
    "\n",
    "# Compute the cosine similarity between the first sentence and each sentence in the list\n",
    "similarities = util.pytorch_cos_sim(embedding1, embeddings2)\n",
    "\n",
    "# Print the similarity scores\n",
    "for i, similarity in enumerate(similarities[0]):\n",
    "    print(f\"Similarity with sentence {i + 1}: {similarity.item()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-07T12:40:00.804044Z",
     "end_time": "2024-08-07T12:40:00.944216Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity with sentence 1: 0.03498101234436035\n",
      "Similarity with sentence 2: 0.04984527826309204\n",
      "Similarity with sentence 3: 0.08021058142185211\n",
      "Similarity with sentence 4: 0.12176443636417389\n"
     ]
    }
   ],
   "source": [
    "# Define your sentences\n",
    "sentence1 = \"[USER_PROFILE] occupation: doctor/health care [SEP] gender: Male\"\n",
    "sentence2_list = [\n",
    "    \"[MOVIE_DETAIL] title: Godfather, The [SEP] genres: Action, Crime, Drama [SEP] year: 1934\",\n",
    "    \"[MOVIE_DETAIL] title: Godfather, The [SEP] genres: Action|Crime|Drama [SEP] year: 1934\",\n",
    "    \"[MOVIE_DETAIL] title: Godfather, The [SEP] genres: Action, Crime, Drama\",\n",
    "    \"[MOVIE_DETAIL] genres: Action, Crime, Drama\",\n",
    "]\n",
    "\n",
    "# Compute the embedding for the first sentence\n",
    "embedding1 = model.encode(sentence1, convert_to_tensor=True)\n",
    "\n",
    "# Compute the embeddings for the list of sentences\n",
    "embeddings2 = model.encode(sentence2_list, convert_to_tensor=True)\n",
    "\n",
    "# Compute the cosine similarity between the first sentence and each sentence in the list\n",
    "similarities = util.pytorch_cos_sim(embedding1, embeddings2)\n",
    "\n",
    "# Print the similarity scores\n",
    "for i, similarity in enumerate(similarities[0]):\n",
    "    print(f\"Similarity with sentence {i + 1}: {similarity.item()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-07T12:40:01.458388Z",
     "end_time": "2024-08-07T12:40:01.598381Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity with sentence 1: 0.2262524962425232\n",
      "Similarity with sentence 2: 0.22121018171310425\n",
      "Similarity with sentence 3: 0.21723076701164246\n"
     ]
    }
   ],
   "source": [
    "# Define your sentences\n",
    "# Action|Crime|Drama\n",
    "sentence1 = \"occupation: doctor/health care [SEP] gender: Male [SEP] history: Godfather, The\"\n",
    "sentence2_list = [\n",
    "    \"title: Silence of the Lambs, The [SEP] genres: Drama, Thriller [SEP] year: 1934\",\n",
    "    \"title: Silence of the Lambs, The [SEP] genres: Drama|Thriller [SEP] year: 1934\",\n",
    "    \"title: Silence of the Lambs, The [SEP] genres: Drama, Thriller\",\n",
    "]\n",
    "\n",
    "# Compute the embedding for the first sentence\n",
    "embedding1 = model.encode(sentence1, convert_to_tensor=True)\n",
    "\n",
    "# Compute the embeddings for the list of sentences\n",
    "embeddings2 = model.encode(sentence2_list, convert_to_tensor=True)\n",
    "\n",
    "# Compute the cosine similarity between the first sentence and each sentence in the list\n",
    "similarities = util.pytorch_cos_sim(embedding1, embeddings2)\n",
    "\n",
    "# Print the similarity scores\n",
    "for i, similarity in enumerate(similarities[0]):\n",
    "    print(f\"Similarity with sentence {i + 1}: {similarity.item()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-07T12:49:24.638449Z",
     "end_time": "2024-08-07T12:49:24.797261Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity with sentence 1: 0.2127831131219864\n",
      "Similarity with sentence 2: 0.21011391282081604\n",
      "Similarity with sentence 3: 0.20810657739639282\n",
      "Similarity with sentence 4: 0.31771332025527954\n",
      "Similarity with sentence 5: 0.31849685311317444\n",
      "Similarity with sentence 6: 0.2967834770679474\n"
     ]
    }
   ],
   "source": [
    "# Define your sentences\n",
    "sentence1 = \"occupation: doctor/health care [SEP] gender: Male [SEP] history: Godfather, Bound\"\n",
    "# sentence1 = \"[USER_PROFILE] occupation: doctor/health care [SEP] gender: Male [SEP] history: Godfather, The, Bound (1996)\"\n",
    "# Bound (1996) Crime|Drama|Romance|Thriller\n",
    "sentence2_list = [\n",
    "    # \"[MOVIE_DETAIL] title: Godfather, The [SEP] genres: Action, Crime, Drama [SEP] year: 1934\",\n",
    "    # \"[MOVIE_DETAIL] title: Godfather, The [SEP] genres: Action, Crime, Drama\",\n",
    "    \"title: Silence of the Lambs, The [SEP] genres: Drama, Thriller [SEP] year: 1934\",\n",
    "    \"title: Silence of the Lambs, The [SEP] genres: Drama|Thriller [SEP] year: 1934\",\n",
    "    \"title: Silence of the Lambs, The [SEP] genres: Drama, Thriller\",\n",
    "    \"Pillow Book, The [SEP] genres: Drama, Romance [SEP] year: 1934\",\n",
    "    \"Pillow Book, The [SEP] genres: Drama|Romance[SEP] year: 1934\",\n",
    "    \"title: Pillow Book, The [SEP] genres: Drama, Romance\",\n",
    "]\n",
    "# Pillow Book, The (1995) Drama|Romance\n",
    "# Compute the embedding for the first sentence\n",
    "embedding1 = model.encode(sentence1, convert_to_tensor=True)\n",
    "\n",
    "# Compute the embeddings for the list of sentences\n",
    "embeddings2 = model.encode(sentence2_list, convert_to_tensor=True)\n",
    "\n",
    "# Compute the cosine similarity between the first sentence and each sentence in the list\n",
    "similarities = util.pytorch_cos_sim(embedding1, embeddings2)\n",
    "\n",
    "# Print the similarity scores\n",
    "for i, similarity in enumerate(similarities[0]):\n",
    "    print(f\"Similarity with sentence {i + 1}: {similarity.item()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-07T17:42:13.641837Z",
     "end_time": "2024-08-07T17:42:15.024268Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity with sentence 1: 0.5501798391342163\n",
      "Similarity with sentence 2: 0.5624335408210754\n",
      "Similarity with sentence 3: 0.5433527231216431\n"
     ]
    }
   ],
   "source": [
    "# Define your sentences\n",
    "sentence1 = \"occupation: doctor/health care [SEP] gender: Male [SEP] history: \" \\\n",
    "            \"title: Godfather, genres:Action|Crime|Drama \" \\\n",
    "            \"title: Bound, genres:Crime|Drama|Romance|Thriller\"\n",
    "# sentence1 = \"[USER_PROFILE] occupation: doctor/health care [SEP] gender: Male [SEP] history: Godfather, The, Bound (1996)\"\n",
    "# Bound (1996) Crime|Drama|Romance|Thriller\n",
    "sentence2_list = [\n",
    "    # \"title: Silence of the Lambs, The [SEP] genres: Drama, Thriller [SEP] year: 1934\",\n",
    "    # \"title: Silence of the Lambs, The [SEP] genres: Drama|Thriller [SEP] year: 1934\",\n",
    "    # \"title: Silence of the Lambs, The [SEP] genres: Drama, Thriller\",\n",
    "    # \"title: Pillow Book, The [SEP] genres: Drama, Romance [SEP] year: 1934\",\n",
    "    # \"Pillow Book, The [SEP] genres: Drama|Romance[SEP] year: 1934\",\n",
    "    # \"title: Pillow Book, The [SEP] genres: Drama, Romance\",\n",
    "    \"Silence of the Lambs [SEP] genres: Drama|Thriller\",\n",
    "    \"Pillow Book [SEP] genres: Drama, Romance\",\n",
    "    \"Carpool [SEP] genres: Comedy, Crime\"\n",
    "]\n",
    "# Pillow Book, The (1995) Drama|Romance\n",
    "# Compute the embedding for the first sentence\n",
    "embedding1 = model.encode(sentence1, convert_to_tensor=True)\n",
    "\n",
    "# Compute the embeddings for the list of sentences\n",
    "embeddings2 = model.encode(sentence2_list, convert_to_tensor=True)\n",
    "\n",
    "# Compute the cosine similarity between the first sentence and each sentence in the list\n",
    "similarities = util.pytorch_cos_sim(embedding1, embeddings2)\n",
    "# Print the similarity scores\n",
    "for i, similarity in enumerate(similarities[0]):\n",
    "    print(f\"Similarity with sentence {i + 1}: {similarity.item()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-07T18:28:35.568973Z",
     "end_time": "2024-08-07T18:28:35.613732Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity with sentence 1: 0.5862199664115906\n",
      "Similarity with sentence 2: 0.46231943368911743\n",
      "Similarity with sentence 3: 0.5660261511802673\n",
      "Similarity with sentence 4: 0.4793689250946045\n",
      "Similarity with sentence 5: 0.4359447956085205\n",
      "Similarity with sentence 6: 0.5242535471916199\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Define your sentences\n",
    "\n",
    "sentence1 = {\n",
    "    \"occupation_gender\": \"[USER_PROFILE] occupation: doctor/health care [SEP] gender: Male\",\n",
    "    \"history\": \"title: Godfather, genres:Action|Crime|Drama [SEP] title: Seven Samurai, genres:Action|Drama [SEP] title: Silence of the Lambs, genres:Drama|Thriller\"\n",
    "}\n",
    "\n",
    "sentence2_list = [\n",
    "    {\"title\": \"Silence of the Lambs\", \"genres\": \"Drama, Thriller\"},\n",
    "    {\"title\": \"Rain Man\", \"genres\": \"Drama\"},\n",
    "    {\"title\": \"Godfather 2\", \"genres\": \"Action|Drama\"},\n",
    "    {\"title\": \"Pillow Book\", \"genres\": \"Drama|Romance\"},\n",
    "    {\"title\": \"Carpool\", \"genres\": \"Comedy|Crime\"},\n",
    "    {\"title\": \"Crying Game\", \"genres\": \"Drama|Romance|War\"}\n",
    "]\n",
    "\n",
    "# Define weights for each part\n",
    "weights1 = {\"occupation_gender\": 0.1, \"history\": 0.9}\n",
    "weights2 = {\"title\": 0.2, \"genres\": 0.8}\n",
    "\n",
    "# Compute embeddings for each part of sentence1\n",
    "embedding1_parts = {key: model.encode(value, convert_to_tensor=True) for key, value in sentence1.items()}\n",
    "weighted_embedding1 = torch.stack([weights1[key] * embedding for key, embedding in embedding1_parts.items()]).sum(dim=0)\n",
    "\n",
    "# Compute weighted embeddings for each sentence in sentence2_list\n",
    "weighted_embeddings2 = []\n",
    "for sentence2_parts in sentence2_list:\n",
    "    embedding2_parts = {key: model.encode(value, convert_to_tensor=True) for key, value in sentence2_parts.items()}\n",
    "    weighted_embedding2 = torch.stack([weights2[key] * embedding for key, embedding in embedding2_parts.items()]).sum(dim=0)\n",
    "    weighted_embeddings2.append(weighted_embedding2)\n",
    "\n",
    "weighted_embeddings2 = torch.stack(weighted_embeddings2)\n",
    "\n",
    "# Compute the cosine similarity between the weighted embedding of sentence1 and each weighted embedding in sentence2_list\n",
    "similarities = util.pytorch_cos_sim(weighted_embedding1, weighted_embeddings2)\n",
    "\n",
    "# Print the similarity scores\n",
    "for i, similarity in enumerate(similarities[0]):\n",
    "    print(f\"Similarity with sentence {i + 1}: {similarity.item()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-07T19:16:12.117158Z",
     "end_time": "2024-08-07T19:16:12.229276Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity with sentence 1: 0.8896061182022095\n",
      "Similarity with sentence 2: 0.8496407270431519\n",
      "Similarity with sentence 3: 0.9223478436470032\n",
      "Similarity with sentence 4: 0.7832946181297302\n",
      "Similarity with sentence 5: 0.6743572950363159\n",
      "Similarity with sentence 6: 0.760257363319397\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define your sentences\n",
    "sentence1 = {\n",
    "    \"occupation_gender\": \"occupation: doctor/health care [SEP] gender: Male\",\n",
    "    \"history\": [\n",
    "        {\"title\": \"Godfather\", \"genres\": \"Action|Crime|Drama\"},\n",
    "        {\"title\": \"Seven Samurai\", \"genres\": \"Action|Drama\"},\n",
    "        {\"title\": \"Silence of the Lambs\", \"genres\": \"Drama|Thriller\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "sentence2_list = [\n",
    "    {\"title\": \"Silence of the Lambs\", \"genres\": \"Drama, Thriller\"},\n",
    "    {\"title\": \"Rain Man\", \"genres\": \"Drama\"},\n",
    "    {\"title\": \"Godfather 2\", \"genres\": \"Action|Drama\"},\n",
    "    {\"title\": \"Pillow Book\", \"genres\": \"Drama|Romance\"},\n",
    "    {\"title\": \"Carpool\", \"genres\": \"Comedy|Crime\"},\n",
    "    {\"title\": \"Crying Game\", \"genres\": \"Drama|Romance|War\"}\n",
    "]\n",
    "\n",
    "# Define weights for each part\n",
    "weights1 = {\"occupation_gender\": 0.1, \"history\": 0.9}\n",
    "history_weights = [0.2, 0.3, 0.5]  # Weights for each movie in history\n",
    "weights2 = {\"title\": 0.2, \"genres\": 0.8}\n",
    "\n",
    "# Compute embeddings for the occupation_gender part of sentence1\n",
    "embedding1_occupation_gender = model.encode(sentence1[\"occupation_gender\"], convert_to_tensor=True)\n",
    "\n",
    "# Compute embeddings for each movie in the history part of sentence1\n",
    "history_embeddings = []\n",
    "for i, movie in enumerate(sentence1[\"history\"]):\n",
    "    title_embedding = model.encode(movie[\"title\"], convert_to_tensor=True)\n",
    "    genres_embedding = model.encode(movie[\"genres\"], convert_to_tensor=True)\n",
    "    movie_embedding = weights2[\"title\"] * title_embedding + weights2[\"genres\"] * genres_embedding\n",
    "    weighted_movie_embedding = history_weights[i] * movie_embedding\n",
    "    history_embeddings.append(weighted_movie_embedding)\n",
    "\n",
    "# Combine the weighted history embeddings\n",
    "weighted_history_embedding = torch.stack(history_embeddings).sum(dim=0)\n",
    "\n",
    "# Combine occupation_gender and history embeddings with their respective weights\n",
    "weighted_embedding1 = weights1[\"occupation_gender\"] * embedding1_occupation_gender + weights1[\"history\"] * weighted_history_embedding\n",
    "\n",
    "# Compute weighted embeddings for each sentence in sentence2_list\n",
    "weighted_embeddings2 = []\n",
    "for sentence2_parts in sentence2_list:\n",
    "    title_embedding = model.encode(sentence2_parts[\"title\"], convert_to_tensor=True)\n",
    "    genres_embedding = model.encode(sentence2_parts[\"genres\"], convert_to_tensor=True)\n",
    "    weighted_embedding2 = weights2[\"title\"] * title_embedding + weights2[\"genres\"] * genres_embedding\n",
    "    weighted_embeddings2.append(weighted_embedding2)\n",
    "\n",
    "weighted_embeddings2 = torch.stack(weighted_embeddings2)\n",
    "# Compute the cosine similarity between the weighted embedding of sentence1 and each weighted embedding in sentence2_list\n",
    "similarities = util.pytorch_cos_sim(weighted_embedding1, weighted_embeddings2)\n",
    "\n",
    "# Print the similarity scores\n",
    "for i, similarity in enumerate(similarities[0]):\n",
    "    print(f\"Similarity with sentence {i + 1}: {similarity.item()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-07T20:50:00.930439Z",
     "end_time": "2024-08-07T20:50:01.095650Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'NVIDIA GeForce RTX 3060 Laptop GPU'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.get_device_name(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-10T11:11:11.198288Z",
     "end_time": "2024-08-10T11:11:11.248580Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['title: Inception [SEP] genres: Action, Sci-Fi', 'title: The Matrix [SEP] genres: Action, Sci-Fi', 'title: Interstellar [SEP] genres: Adventure, Drama']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Set device to GPU if available, otherwise CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class RecommenderSystem:\n",
    "    def __init__(self):\n",
    "        self.user_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "        self.item_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "    def compute_weighted_user_embedding(self, user_text):\n",
    "        occupation_gender_weight = 0.1\n",
    "        history_weight = 0.9\n",
    "\n",
    "        # Ensure history_weights is on the correct device\n",
    "        history_weights = torch.tensor([0.2, 0.3, 0.5], device=device)\n",
    "\n",
    "        # Compute embeddings for the occupation_gender part of user_text\n",
    "        occupation_gender_embedding = self.user_model.encode(user_text[\"occupation_gender\"], convert_to_tensor=True).to(device)\n",
    "\n",
    "        # Prepare input for batch processing\n",
    "        history_texts = [f\"title: {movie['title']} [SEP] genres: {movie['genres']}\" for movie in user_text[\"history\"]]\n",
    "\n",
    "        if history_texts:\n",
    "            # Batch process embeddings for history\n",
    "            history_embeddings = self.user_model.encode(history_texts, convert_to_tensor=True).to(device)\n",
    "\n",
    "            # Apply weights to embeddings\n",
    "            history_weights_batch = history_weights[:len(history_embeddings)]\n",
    "            weighted_history_embedding = torch.matmul(history_weights_batch, history_embeddings)\n",
    "        else:\n",
    "            weighted_history_embedding = torch.zeros_like(occupation_gender_embedding)\n",
    "\n",
    "        # Combine occupation_gender and history embeddings with their respective weights\n",
    "        weighted_embedding = (occupation_gender_weight * occupation_gender_embedding +\n",
    "                              history_weight * weighted_history_embedding)\n",
    "        print(history_texts)\n",
    "        return weighted_embedding\n",
    "\n",
    "    def compute_weighted_item_embedding(self, item_text):\n",
    "        title_weight = 0.2\n",
    "        genres_weight = 0.8\n",
    "\n",
    "        # Compute embeddings for title and genres\n",
    "        title_embedding = self.item_model.encode(f\"title: {item_text['title']}\", convert_to_tensor=True).to(device)\n",
    "        genres_embedding = self.item_model.encode(f\"genres: {item_text['genres']}\", convert_to_tensor=True).to(device)\n",
    "\n",
    "        # Combine embeddings with their respective weights\n",
    "        weighted_embedding = (title_weight * title_embedding +\n",
    "                              genres_weight * genres_embedding)\n",
    "\n",
    "        return weighted_embedding\n",
    "\n",
    "\n",
    "# Example Input Data\n",
    "user_text = {\n",
    "    \"occupation_gender\": \"software engineer male\",\n",
    "    \"history\": [\n",
    "        {\"title\": \"Inception\", \"genres\": \"Action, Sci-Fi\"},\n",
    "        {\"title\": \"The Matrix\", \"genres\": \"Action, Sci-Fi\"},\n",
    "        {\"title\": \"Interstellar\", \"genres\": \"Adventure, Drama\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "item_text = {\n",
    "    \"title\": \"Inception\",\n",
    "    \"genres\": \"Action, Sci-Fi\"\n",
    "}\n",
    "\n",
    "# Initialize RecommenderSystem\n",
    "recommender = RecommenderSystem()\n",
    "\n",
    "# Compute embeddings\n",
    "user_embedding = recommender.compute_weighted_user_embedding(user_text)\n",
    "item_embedding = recommender.compute_weighted_item_embedding(item_text)\n",
    "\n",
    "# Output embeddings\n",
    "# print(\"User Embedding:\", user_embedding)\n",
    "# print(\"Item Embedding:\", item_embedding)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-10T11:14:19.575324Z",
     "end_time": "2024-08-10T11:14:25.349666Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-10T11:55:37.590826Z",
     "end_time": "2024-08-10T11:55:40.114747Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-15T11:46:54.358988Z",
     "end_time": "2024-08-15T11:46:56.690051Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('processed_dataset/Amazon-Beauty/amazon_beauty_ratings.csv')\n",
    "products = pd.read_csv('processed_dataset/Amazon-Beauty/amazon_beauty_reviews_meta.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-15T17:54:17.256861Z",
     "end_time": "2024-08-15T17:54:22.676978Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "# Remove users with less than 5 interactions\n",
    "user_interactions = ratings['user_id'].value_counts()\n",
    "users_to_keep = user_interactions[user_interactions >= 2].index\n",
    "filtered_ratings = ratings[ratings['user_id'].isin(users_to_keep)]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-15T17:54:22.677978Z",
     "end_time": "2024-08-15T17:54:23.298195Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "        rating                                              title  \\\n0            5          Such a lovely scent but not overpowering.   \n1            4             Works great but smells a little weird.   \n3            1                                  Synthetic feeling   \n4            5                                                 A+   \n8            5          Great for at home use and so easy to use!   \n...        ...                                                ...   \n701456       2                       Cute but not water resistant   \n701474       5  Easy replacement after i dumped a water bottle...   \n701477       5  Easy replacement after i dumped a water bottle...   \n701518       1                                           One Star   \n701519       1                                           One Star   \n\n                                                     text images        asin  \\\n0       This spray is really nice. It smells really go...     []  B00YQ6X8EO   \n1       This product does what I need it to do, I just...     []  B081TJ8YS3   \n3                                          Felt synthetic     []  B09JS339BZ   \n4                                                 Love it     []  B08BZ63GMJ   \n8       This is perfect for my between salon visits. I...     []  B08P2DZB4X   \n...                                                   ...    ...         ...   \n701456  I think the design of the caps is so cute, but...     []  B08CDWBNWC   \n701474  I used nylon interior trim removal tools, from...     []  B07HC84V8D   \n701477  I used nylon interior trim removal tools, from...     []  B07HC84V8D   \n701518  Cant do anything with it. No Heat, cant get it...     []  B01HO3M2II   \n701519  Cant do anything with it. No Heat, cant get it...     []  B01HO3M2II   \n\n       parent_asin                       user_id     timestamp  \\\n0       B00YQ6X8EO  AGKHLEW2SOWHNMFQIJGBECAF7INQ  1.588690e+12   \n1       B081TJ8YS3  AGKHLEW2SOWHNMFQIJGBECAF7INQ  1.588620e+12   \n3       B09JS339BZ  AFQLNQNQYFWQZPJQZS6V3NZU4QBQ  1.643390e+12   \n4       B08BZ63GMJ  AFQLNQNQYFWQZPJQZS6V3NZU4QBQ  1.609320e+12   \n8       B08P2DZB4X  AFSKPY37N3C43SOI5IEXEK5JSIYA  1.627390e+12   \n...            ...                           ...           ...   \n701456  B08CDWBNWC  AGAM6PJOXCDJLLOPYJVFNILD7DTQ  1.618860e+12   \n701474  B07HC84V8D  AHOBG6Y2ONNVVJJR54QLT3OIVMLA  1.566870e+12   \n701477  B07HC84V8D  AHOBG6Y2ONNVVJJR54QLT3OIVMLA  1.566870e+12   \n701518  B01HO3M2II  AF35ZHUHDHWFRMSP2BBRCTGBUMYA  1.524260e+12   \n701519  B01HO3M2II  AF35ZHUHDHWFRMSP2BBRCTGBUMYA  1.524260e+12   \n\n        verified_purchase  helpful_vote  \n0                    True             0  \n1                    True             1  \n3                    True             0  \n4                    True             0  \n8                   False             0  \n...                   ...           ...  \n701456               True             0  \n701474               True             0  \n701477               True             0  \n701518               True             0  \n701519               True             0  \n\n[117975 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rating</th>\n      <th>title</th>\n      <th>text</th>\n      <th>images</th>\n      <th>asin</th>\n      <th>parent_asin</th>\n      <th>user_id</th>\n      <th>timestamp</th>\n      <th>verified_purchase</th>\n      <th>helpful_vote</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>Such a lovely scent but not overpowering.</td>\n      <td>This spray is really nice. It smells really go...</td>\n      <td>[]</td>\n      <td>B00YQ6X8EO</td>\n      <td>B00YQ6X8EO</td>\n      <td>AGKHLEW2SOWHNMFQIJGBECAF7INQ</td>\n      <td>1.588690e+12</td>\n      <td>True</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>Works great but smells a little weird.</td>\n      <td>This product does what I need it to do, I just...</td>\n      <td>[]</td>\n      <td>B081TJ8YS3</td>\n      <td>B081TJ8YS3</td>\n      <td>AGKHLEW2SOWHNMFQIJGBECAF7INQ</td>\n      <td>1.588620e+12</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Synthetic feeling</td>\n      <td>Felt synthetic</td>\n      <td>[]</td>\n      <td>B09JS339BZ</td>\n      <td>B09JS339BZ</td>\n      <td>AFQLNQNQYFWQZPJQZS6V3NZU4QBQ</td>\n      <td>1.643390e+12</td>\n      <td>True</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>A+</td>\n      <td>Love it</td>\n      <td>[]</td>\n      <td>B08BZ63GMJ</td>\n      <td>B08BZ63GMJ</td>\n      <td>AFQLNQNQYFWQZPJQZS6V3NZU4QBQ</td>\n      <td>1.609320e+12</td>\n      <td>True</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>5</td>\n      <td>Great for at home use and so easy to use!</td>\n      <td>This is perfect for my between salon visits. I...</td>\n      <td>[]</td>\n      <td>B08P2DZB4X</td>\n      <td>B08P2DZB4X</td>\n      <td>AFSKPY37N3C43SOI5IEXEK5JSIYA</td>\n      <td>1.627390e+12</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>701456</th>\n      <td>2</td>\n      <td>Cute but not water resistant</td>\n      <td>I think the design of the caps is so cute, but...</td>\n      <td>[]</td>\n      <td>B08CDWBNWC</td>\n      <td>B08CDWBNWC</td>\n      <td>AGAM6PJOXCDJLLOPYJVFNILD7DTQ</td>\n      <td>1.618860e+12</td>\n      <td>True</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>701474</th>\n      <td>5</td>\n      <td>Easy replacement after i dumped a water bottle...</td>\n      <td>I used nylon interior trim removal tools, from...</td>\n      <td>[]</td>\n      <td>B07HC84V8D</td>\n      <td>B07HC84V8D</td>\n      <td>AHOBG6Y2ONNVVJJR54QLT3OIVMLA</td>\n      <td>1.566870e+12</td>\n      <td>True</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>701477</th>\n      <td>5</td>\n      <td>Easy replacement after i dumped a water bottle...</td>\n      <td>I used nylon interior trim removal tools, from...</td>\n      <td>[]</td>\n      <td>B07HC84V8D</td>\n      <td>B07HC84V8D</td>\n      <td>AHOBG6Y2ONNVVJJR54QLT3OIVMLA</td>\n      <td>1.566870e+12</td>\n      <td>True</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>701518</th>\n      <td>1</td>\n      <td>One Star</td>\n      <td>Cant do anything with it. No Heat, cant get it...</td>\n      <td>[]</td>\n      <td>B01HO3M2II</td>\n      <td>B01HO3M2II</td>\n      <td>AF35ZHUHDHWFRMSP2BBRCTGBUMYA</td>\n      <td>1.524260e+12</td>\n      <td>True</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>701519</th>\n      <td>1</td>\n      <td>One Star</td>\n      <td>Cant do anything with it. No Heat, cant get it...</td>\n      <td>[]</td>\n      <td>B01HO3M2II</td>\n      <td>B01HO3M2II</td>\n      <td>AF35ZHUHDHWFRMSP2BBRCTGBUMYA</td>\n      <td>1.524260e+12</td>\n      <td>True</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>117975 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_ratings"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-15T17:54:23.307190Z",
     "end_time": "2024-08-15T17:54:23.312181Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "ratings = filtered_ratings.sort_values(by='timestamp')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-15T17:55:13.623486Z",
     "end_time": "2024-08-15T17:55:13.712000Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "ratings = ratings.drop(columns=['images', 'verified_purchase', 'helpful_vote', 'text'])\n",
    "ratings = ratings.sort_values(by='timestamp')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-15T17:55:14.360801Z",
     "end_time": "2024-08-15T17:55:14.411827Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "        rating                                              title        asin  \\\n597043       4  Timer toothbrush is good- but does not last fo...  B000050FDB   \n597044       4  Timer toothbrush is good- but does not last fo...  B000050FDB   \n385803       3            Spectra not Spectacular; Only its Price  B000068PBJ   \n293364       3                                         I agree...  B000068PBP   \n334056       4                       It does a great job, but ...  B000068PBR   \n...        ...                                                ...         ...   \n692493       5                                            Natural  B0BCTVP9ND   \n692492       5                                            Natural  B0BCTVP9ND   \n698001       5                                       Recommended!  B0C1Z62W23   \n698000       5                                       Recommended!  B0C1Z62W23   \n701439       1                                               Hurt  B0CBBZ9MJ4   \n\n       parent_asin                       user_id     timestamp  \n597043  B000050FDB  AFZJZJXW4JCY4MWCV6FX5RRPRMYA  9.882960e+11  \n597044  B000050FDB  AFZJZJXW4JCY4MWCV6FX5RRPRMYA  9.882960e+11  \n385803  B000068PBJ  AELUS5EVZT4256ZTANHE7TN5MH6Q  1.040960e+12  \n293364  B000068PBP  AHGFST33AIE4TMZEMQ7ZZWR26EZQ  1.042270e+12  \n334056  B000068PBR  AFQHRQCEKX3W533NRYKHZF2WRYQQ  1.053150e+12  \n...            ...                           ...           ...  \n692493  B0BTLTVR1X  AE7JOTC5NKTZ5WONQ4SIP2YJFFAA  1.693440e+12  \n692492  B0BTLTVR1X  AE7JOTC5NKTZ5WONQ4SIP2YJFFAA  1.693440e+12  \n698001  B0BTLTVR1X  AGI5NDMAHRCA2CXXZMFGA2AKSIZA  1.693610e+12  \n698000  B0BTLTVR1X  AGI5NDMAHRCA2CXXZMFGA2AKSIZA  1.693610e+12  \n701439  B0CBBZ9MJ4  AHURE3VT2MLCTARMYI7JA7KKDYAA  1.694220e+12  \n\n[117975 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rating</th>\n      <th>title</th>\n      <th>asin</th>\n      <th>parent_asin</th>\n      <th>user_id</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>597043</th>\n      <td>4</td>\n      <td>Timer toothbrush is good- but does not last fo...</td>\n      <td>B000050FDB</td>\n      <td>B000050FDB</td>\n      <td>AFZJZJXW4JCY4MWCV6FX5RRPRMYA</td>\n      <td>9.882960e+11</td>\n    </tr>\n    <tr>\n      <th>597044</th>\n      <td>4</td>\n      <td>Timer toothbrush is good- but does not last fo...</td>\n      <td>B000050FDB</td>\n      <td>B000050FDB</td>\n      <td>AFZJZJXW4JCY4MWCV6FX5RRPRMYA</td>\n      <td>9.882960e+11</td>\n    </tr>\n    <tr>\n      <th>385803</th>\n      <td>3</td>\n      <td>Spectra not Spectacular; Only its Price</td>\n      <td>B000068PBJ</td>\n      <td>B000068PBJ</td>\n      <td>AELUS5EVZT4256ZTANHE7TN5MH6Q</td>\n      <td>1.040960e+12</td>\n    </tr>\n    <tr>\n      <th>293364</th>\n      <td>3</td>\n      <td>I agree...</td>\n      <td>B000068PBP</td>\n      <td>B000068PBP</td>\n      <td>AHGFST33AIE4TMZEMQ7ZZWR26EZQ</td>\n      <td>1.042270e+12</td>\n    </tr>\n    <tr>\n      <th>334056</th>\n      <td>4</td>\n      <td>It does a great job, but ...</td>\n      <td>B000068PBR</td>\n      <td>B000068PBR</td>\n      <td>AFQHRQCEKX3W533NRYKHZF2WRYQQ</td>\n      <td>1.053150e+12</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>692493</th>\n      <td>5</td>\n      <td>Natural</td>\n      <td>B0BCTVP9ND</td>\n      <td>B0BTLTVR1X</td>\n      <td>AE7JOTC5NKTZ5WONQ4SIP2YJFFAA</td>\n      <td>1.693440e+12</td>\n    </tr>\n    <tr>\n      <th>692492</th>\n      <td>5</td>\n      <td>Natural</td>\n      <td>B0BCTVP9ND</td>\n      <td>B0BTLTVR1X</td>\n      <td>AE7JOTC5NKTZ5WONQ4SIP2YJFFAA</td>\n      <td>1.693440e+12</td>\n    </tr>\n    <tr>\n      <th>698001</th>\n      <td>5</td>\n      <td>Recommended!</td>\n      <td>B0C1Z62W23</td>\n      <td>B0BTLTVR1X</td>\n      <td>AGI5NDMAHRCA2CXXZMFGA2AKSIZA</td>\n      <td>1.693610e+12</td>\n    </tr>\n    <tr>\n      <th>698000</th>\n      <td>5</td>\n      <td>Recommended!</td>\n      <td>B0C1Z62W23</td>\n      <td>B0BTLTVR1X</td>\n      <td>AGI5NDMAHRCA2CXXZMFGA2AKSIZA</td>\n      <td>1.693610e+12</td>\n    </tr>\n    <tr>\n      <th>701439</th>\n      <td>1</td>\n      <td>Hurt</td>\n      <td>B0CBBZ9MJ4</td>\n      <td>B0CBBZ9MJ4</td>\n      <td>AHURE3VT2MLCTARMYI7JA7KKDYAA</td>\n      <td>1.694220e+12</td>\n    </tr>\n  </tbody>\n</table>\n<p>117975 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-15T17:55:15.419950Z",
     "end_time": "2024-08-15T17:55:15.450951Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "# Split the data into 8:1:1 for training, validation, and test sets\n",
    "train_size = int(0.8 * len(ratings))\n",
    "valid_size = int(0.1 * len(ratings))\n",
    "test_size = len(ratings) - train_size - valid_size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-15T17:55:17.431026Z",
     "end_time": "2024-08-15T17:55:17.443028Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "train_set = ratings[:train_size]\n",
    "valid_set = ratings[train_size:train_size + valid_size]\n",
    "test_set = ratings[train_size + valid_size:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-15T17:55:17.831416Z",
     "end_time": "2024-08-15T17:55:17.890233Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "        rating                                   title        asin  \\\n79430        5                   Nice variety of color  B08YZ3854D   \n210297       5                            He loves it!  B097CMPW2L   \n484168       5                                Awesome!  B08HGHZLG4   \n196774       4                       Worth every penny  B085NPFN6Q   \n246344       5  Very Good Eyeshadow Just What I Wanted  B07Z9MQKS3   \n...        ...                                     ...         ...   \n692493       5                                 Natural  B0BCTVP9ND   \n692492       5                                 Natural  B0BCTVP9ND   \n698001       5                            Recommended!  B0C1Z62W23   \n698000       5                            Recommended!  B0C1Z62W23   \n701439       1                                    Hurt  B0CBBZ9MJ4   \n\n       parent_asin                       user_id     timestamp  \n79430   B08YZ3854D  AEWUWC3QEJ5ZXJ2R6ERWG6OQWQBQ  1.642620e+12  \n210297  B0C619KBLQ  AGPMUNWUHM6UED3E2BLSIBMIQJ2A  1.642620e+12  \n484168  B08HGHZLG4  AG5V5E75PRPAMFDKAXX5GNWWPSXA  1.642620e+12  \n196774  B085NPFN6Q  AEG6XY5WSQSFUE6ZWNGNRN5ZW6WA  1.642620e+12  \n246344  B07Z9MQKS3  AGXH5VMZ44KGOXZ7WVS4H63FHHQA  1.642620e+12  \n...            ...                           ...           ...  \n692493  B0BTLTVR1X  AE7JOTC5NKTZ5WONQ4SIP2YJFFAA  1.693440e+12  \n692492  B0BTLTVR1X  AE7JOTC5NKTZ5WONQ4SIP2YJFFAA  1.693440e+12  \n698001  B0BTLTVR1X  AGI5NDMAHRCA2CXXZMFGA2AKSIZA  1.693610e+12  \n698000  B0BTLTVR1X  AGI5NDMAHRCA2CXXZMFGA2AKSIZA  1.693610e+12  \n701439  B0CBBZ9MJ4  AHURE3VT2MLCTARMYI7JA7KKDYAA  1.694220e+12  \n\n[11798 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rating</th>\n      <th>title</th>\n      <th>asin</th>\n      <th>parent_asin</th>\n      <th>user_id</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>79430</th>\n      <td>5</td>\n      <td>Nice variety of color</td>\n      <td>B08YZ3854D</td>\n      <td>B08YZ3854D</td>\n      <td>AEWUWC3QEJ5ZXJ2R6ERWG6OQWQBQ</td>\n      <td>1.642620e+12</td>\n    </tr>\n    <tr>\n      <th>210297</th>\n      <td>5</td>\n      <td>He loves it!</td>\n      <td>B097CMPW2L</td>\n      <td>B0C619KBLQ</td>\n      <td>AGPMUNWUHM6UED3E2BLSIBMIQJ2A</td>\n      <td>1.642620e+12</td>\n    </tr>\n    <tr>\n      <th>484168</th>\n      <td>5</td>\n      <td>Awesome!</td>\n      <td>B08HGHZLG4</td>\n      <td>B08HGHZLG4</td>\n      <td>AG5V5E75PRPAMFDKAXX5GNWWPSXA</td>\n      <td>1.642620e+12</td>\n    </tr>\n    <tr>\n      <th>196774</th>\n      <td>4</td>\n      <td>Worth every penny</td>\n      <td>B085NPFN6Q</td>\n      <td>B085NPFN6Q</td>\n      <td>AEG6XY5WSQSFUE6ZWNGNRN5ZW6WA</td>\n      <td>1.642620e+12</td>\n    </tr>\n    <tr>\n      <th>246344</th>\n      <td>5</td>\n      <td>Very Good Eyeshadow Just What I Wanted</td>\n      <td>B07Z9MQKS3</td>\n      <td>B07Z9MQKS3</td>\n      <td>AGXH5VMZ44KGOXZ7WVS4H63FHHQA</td>\n      <td>1.642620e+12</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>692493</th>\n      <td>5</td>\n      <td>Natural</td>\n      <td>B0BCTVP9ND</td>\n      <td>B0BTLTVR1X</td>\n      <td>AE7JOTC5NKTZ5WONQ4SIP2YJFFAA</td>\n      <td>1.693440e+12</td>\n    </tr>\n    <tr>\n      <th>692492</th>\n      <td>5</td>\n      <td>Natural</td>\n      <td>B0BCTVP9ND</td>\n      <td>B0BTLTVR1X</td>\n      <td>AE7JOTC5NKTZ5WONQ4SIP2YJFFAA</td>\n      <td>1.693440e+12</td>\n    </tr>\n    <tr>\n      <th>698001</th>\n      <td>5</td>\n      <td>Recommended!</td>\n      <td>B0C1Z62W23</td>\n      <td>B0BTLTVR1X</td>\n      <td>AGI5NDMAHRCA2CXXZMFGA2AKSIZA</td>\n      <td>1.693610e+12</td>\n    </tr>\n    <tr>\n      <th>698000</th>\n      <td>5</td>\n      <td>Recommended!</td>\n      <td>B0C1Z62W23</td>\n      <td>B0BTLTVR1X</td>\n      <td>AGI5NDMAHRCA2CXXZMFGA2AKSIZA</td>\n      <td>1.693610e+12</td>\n    </tr>\n    <tr>\n      <th>701439</th>\n      <td>1</td>\n      <td>Hurt</td>\n      <td>B0CBBZ9MJ4</td>\n      <td>B0CBBZ9MJ4</td>\n      <td>AHURE3VT2MLCTARMYI7JA7KKDYAA</td>\n      <td>1.694220e+12</td>\n    </tr>\n  </tbody>\n</table>\n<p>11798 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-15T17:55:19.597597Z",
     "end_time": "2024-08-15T17:55:19.623596Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "# Sort each set again based on timestamp\n",
    "train_set = train_set.sort_values(by='timestamp')\n",
    "valid_set = valid_set.sort_values(by='timestamp')\n",
    "test_set = test_set.sort_values(by='timestamp')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-15T17:55:21.999114Z",
     "end_time": "2024-08-15T17:55:22.027113Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "((94380, 6), (11797, 6), (11798, 6))"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape, valid_set.shape, test_set.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-15T17:55:22.886182Z",
     "end_time": "2024-08-15T17:55:22.895182Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "# Save the datasets to CSV files\n",
    "train_set.to_csv('./amazon_beauty_ratings_train.csv', index=False)\n",
    "valid_set.to_csv('./amazon_beauty_ratings_valid.csv', index=False)\n",
    "test_set.to_csv('./amazon_beauty_ratings_test.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-15T17:55:25.100642Z",
     "end_time": "2024-08-15T17:55:25.482660Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "products = products.drop(columns=['images', 'videos', 'categories', 'parent_asin', 'bought_together', 'rating_number', 'price', 'features', 'average_rating'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-15T11:48:56.604697Z",
     "end_time": "2024-08-15T11:48:56.633215Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "       main_category                                              title  \\\n0         All Beauty  Howard LC0008 Leather Conditioner, 8-Ounce (4-...   \n1         All Beauty  Yes to Tomatoes Detoxifying Charcoal Cleanser ...   \n2         All Beauty   Eye Patch Black Adult with Tie Band (6 Per Pack)   \n3         All Beauty  Tattoo Eyebrow Stickers, Waterproof Eyebrow, 4...   \n4         All Beauty  Precision Plunger Bars for Cartridge Grips – 9...   \n...              ...                                                ...   \n112585    All Beauty  TOPREETY 24\"120gr 3/4 Full Head clip in hair e...   \n112586    All Beauty  Pets Playmate Pet Grooming Glove,Gentle Deshed...   \n112587    All Beauty  [10Pack] Makeup Brushes Set Cosmetics Tools Ki...   \n112588    All Beauty  Xcoser Pretty Party Anna Wig Hair Tails Hair S...   \n112589    All Beauty  DVIO Men's Voyage Perfume, Spicy woody fragran...   \n\n                                              description  \\\n0                                                      []   \n1                                                      []   \n2                                                      []   \n3                                                      []   \n4       ['The Precision Plunger Bars are designed to w...   \n...                                                   ...   \n112585                                                 []   \n112586                                                 []   \n112587                                                 []   \n112588                                                 []   \n112589                                                 []   \n\n                         store  \\\n0              Howard Products   \n1                       Yes To   \n2       Levine Health Products   \n3                     Cherioll   \n4                    Precision   \n...                        ...   \n112585                TOPREETY   \n112586           Pets Playmate   \n112587              RainMakers   \n112588                  Xcoser   \n112589                    DVIO   \n\n                                                  details  \n0       {'Package Dimensions': '7.1 x 5.5 x 3 inches; ...  \n1       {'Item Form': 'Powder', 'Skin Type': 'Acne Pro...  \n2              {'Manufacturer': 'Levine Health Products'}  \n3       {'Brand': 'Cherioll', 'Item Form': 'Powder', '...  \n4                                 {'UPC': '644287689178'}  \n...                                                   ...  \n112585  {'Is Discontinued By Manufacturer': 'No', 'Pac...  \n112586  {'Is Discontinued By Manufacturer': 'No', 'Pac...  \n112587  {'Brand': 'RainMakers', 'Recommended Uses For ...  \n112588  {'Is Discontinued By Manufacturer': 'No', 'Pac...  \n112589    {'UPC': '736238729337', 'Manufacturer': 'DVIO'}  \n\n[112590 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>main_category</th>\n      <th>title</th>\n      <th>description</th>\n      <th>store</th>\n      <th>details</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>All Beauty</td>\n      <td>Howard LC0008 Leather Conditioner, 8-Ounce (4-...</td>\n      <td>[]</td>\n      <td>Howard Products</td>\n      <td>{'Package Dimensions': '7.1 x 5.5 x 3 inches; ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>All Beauty</td>\n      <td>Yes to Tomatoes Detoxifying Charcoal Cleanser ...</td>\n      <td>[]</td>\n      <td>Yes To</td>\n      <td>{'Item Form': 'Powder', 'Skin Type': 'Acne Pro...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>All Beauty</td>\n      <td>Eye Patch Black Adult with Tie Band (6 Per Pack)</td>\n      <td>[]</td>\n      <td>Levine Health Products</td>\n      <td>{'Manufacturer': 'Levine Health Products'}</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>All Beauty</td>\n      <td>Tattoo Eyebrow Stickers, Waterproof Eyebrow, 4...</td>\n      <td>[]</td>\n      <td>Cherioll</td>\n      <td>{'Brand': 'Cherioll', 'Item Form': 'Powder', '...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>All Beauty</td>\n      <td>Precision Plunger Bars for Cartridge Grips – 9...</td>\n      <td>['The Precision Plunger Bars are designed to w...</td>\n      <td>Precision</td>\n      <td>{'UPC': '644287689178'}</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>112585</th>\n      <td>All Beauty</td>\n      <td>TOPREETY 24\"120gr 3/4 Full Head clip in hair e...</td>\n      <td>[]</td>\n      <td>TOPREETY</td>\n      <td>{'Is Discontinued By Manufacturer': 'No', 'Pac...</td>\n    </tr>\n    <tr>\n      <th>112586</th>\n      <td>All Beauty</td>\n      <td>Pets Playmate Pet Grooming Glove,Gentle Deshed...</td>\n      <td>[]</td>\n      <td>Pets Playmate</td>\n      <td>{'Is Discontinued By Manufacturer': 'No', 'Pac...</td>\n    </tr>\n    <tr>\n      <th>112587</th>\n      <td>All Beauty</td>\n      <td>[10Pack] Makeup Brushes Set Cosmetics Tools Ki...</td>\n      <td>[]</td>\n      <td>RainMakers</td>\n      <td>{'Brand': 'RainMakers', 'Recommended Uses For ...</td>\n    </tr>\n    <tr>\n      <th>112588</th>\n      <td>All Beauty</td>\n      <td>Xcoser Pretty Party Anna Wig Hair Tails Hair S...</td>\n      <td>[]</td>\n      <td>Xcoser</td>\n      <td>{'Is Discontinued By Manufacturer': 'No', 'Pac...</td>\n    </tr>\n    <tr>\n      <th>112589</th>\n      <td>All Beauty</td>\n      <td>DVIO Men's Voyage Perfume, Spicy woody fragran...</td>\n      <td>[]</td>\n      <td>DVIO</td>\n      <td>{'UPC': '736238729337', 'Manufacturer': 'DVIO'}</td>\n    </tr>\n  </tbody>\n</table>\n<p>112590 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-15T11:48:57.239966Z",
     "end_time": "2024-08-15T11:48:57.261962Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the datasets\n",
    "ratings = pd.read_csv('processed_dataset/Amazon-Beauty/amazon_beauty_ratings.csv')\n",
    "products = pd.read_csv('processed_dataset/Amazon-Beauty/amazon_beauty_reviews_meta.csv')\n",
    "\n",
    "# Remove users with less than 5 interactions\n",
    "user_interactions = ratings['user_id'].value_counts()\n",
    "users_to_keep = user_interactions[user_interactions >= 10].index\n",
    "filtered_ratings = ratings[ratings['user_id'].isin(users_to_keep)]\n",
    "\n",
    "# Group data by user_id\n",
    "grouped = filtered_ratings.groupby('user_id')\n",
    "\n",
    "# Prepare containers for splits\n",
    "train_list = []\n",
    "val_list = []\n",
    "test_list = []\n",
    "\n",
    "# Define the sizes for validation and test sets\n",
    "val_size = 0.1\n",
    "test_size = 0.1\n",
    "\n",
    "# Process each user's ratings\n",
    "for userId, group in grouped:\n",
    "    # If there are not enough samples, assign all to training set\n",
    "    if len(group) < 3:\n",
    "        train_list.append(group.sort_values(by='timestamp'))\n",
    "        continue\n",
    "\n",
    "    # Split the data for each userId\n",
    "    train_data, temp_data = train_test_split(\n",
    "        group,\n",
    "        test_size=(val_size + test_size),\n",
    "        random_state=42,\n",
    "        shuffle=False  # Preserve timestamp order\n",
    "    )\n",
    "\n",
    "    if len(temp_data) < 2:  # If the temp_data is too small to split, add it all to the train set\n",
    "        train_list.append(train_data.sort_values(by='timestamp'))\n",
    "        continue\n",
    "\n",
    "    val_data, test_data = train_test_split(\n",
    "        temp_data,\n",
    "        test_size=test_size / (val_size + test_size),\n",
    "        random_state=42,\n",
    "        shuffle=False  # Preserve timestamp order\n",
    "    )\n",
    "\n",
    "    # Append sorted data\n",
    "    train_list.append(train_data.sort_values(by='timestamp'))\n",
    "    val_list.append(val_data.sort_values(by='timestamp'))\n",
    "    test_list.append(test_data.sort_values(by='timestamp'))\n",
    "\n",
    "# Concatenate all user-wise splits into final datasets\n",
    "train_set = pd.concat(train_list)\n",
    "val_set = pd.concat(val_list)\n",
    "test_set = pd.concat(test_list)\n",
    "\n",
    "# Save the datasets to CSV files\n",
    "train_set.to_csv('amazon_beauty_ratings_train.csv', index=False)\n",
    "val_set.to_csv('amazon_beauty_ratings_val.csv', index=False)\n",
    "test_set.to_csv('amazon_beauty_ratings_test.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-16T12:50:26.945069Z",
     "end_time": "2024-08-16T12:50:35.989584Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "        rating                                      title  \\\n8            5  Great for at home use and so easy to use!   \n9            5                 Nice shampoo for the money   \n10           3      Not what I thought I would be getting   \n11           5                  A little goes a long way!   \n12           3                                    Just ok   \n...        ...                                        ...   \n695780       1      Product works-ish, very lazy packing.   \n695781       1      Product works-ish, very lazy packing.   \n695783       1      Product works-ish, very lazy packing.   \n695785       1      Product works-ish, very lazy packing.   \n695786       1      Product works-ish, very lazy packing.   \n\n                                                     text images        asin  \\\n8       This is perfect for my between salon visits. I...     []  B08P2DZB4X   \n9       I get Keratin treatments at the salon at least...     []  B086QY6T7N   \n10      I was very disappointed when I got this facial...     []  B08DHTJ25J   \n11      This is a really nice moisturizing lotion. It ...     []  B07RBSLNFR   \n12      I try to get Keratin treatments every 3 months...     []  B07SLFWZKN   \n...                                                   ...    ...         ...   \n695780  Kinda mad that i picked this poly gel set bc i...     []  B07PX9J8YJ   \n695781  Kinda mad that i picked this poly gel set bc i...     []  B07PX9J8YJ   \n695783  Kinda mad that i picked this poly gel set bc i...     []  B07PX9J8YJ   \n695785  Kinda mad that i picked this poly gel set bc i...     []  B07PX9J8YJ   \n695786  Kinda mad that i picked this poly gel set bc i...     []  B07PX9J8YJ   \n\n       parent_asin                       user_id     timestamp  \\\n8       B08P2DZB4X  AFSKPY37N3C43SOI5IEXEK5JSIYA  1.627390e+12   \n9       B086QY6T7N  AFSKPY37N3C43SOI5IEXEK5JSIYA  1.626610e+12   \n10      B08DHTJ25J  AFSKPY37N3C43SOI5IEXEK5JSIYA  1.626210e+12   \n11      B07RBSLNFR  AFSKPY37N3C43SOI5IEXEK5JSIYA  1.621180e+12   \n12      B07SLFWZKN  AFSKPY37N3C43SOI5IEXEK5JSIYA  1.619740e+12   \n...            ...                           ...           ...   \n695780  B07PX9J8YJ  AEUGNUJOAKJNWDHART2SX6VBTJ6A  1.608740e+12   \n695781  B07PX9J8YJ  AEUGNUJOAKJNWDHART2SX6VBTJ6A  1.608740e+12   \n695783  B07PX9J8YJ  AEUGNUJOAKJNWDHART2SX6VBTJ6A  1.608740e+12   \n695785  B07PX9J8YJ  AEUGNUJOAKJNWDHART2SX6VBTJ6A  1.608740e+12   \n695786  B07PX9J8YJ  AEUGNUJOAKJNWDHART2SX6VBTJ6A  1.608740e+12   \n\n        verified_purchase  helpful_vote  \n8                   False             0  \n9                   False             0  \n10                  False             0  \n11                  False             0  \n12                  False             0  \n...                   ...           ...  \n695780              False             1  \n695781              False             1  \n695783              False             1  \n695785              False             1  \n695786              False             1  \n\n[14984 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rating</th>\n      <th>title</th>\n      <th>text</th>\n      <th>images</th>\n      <th>asin</th>\n      <th>parent_asin</th>\n      <th>user_id</th>\n      <th>timestamp</th>\n      <th>verified_purchase</th>\n      <th>helpful_vote</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8</th>\n      <td>5</td>\n      <td>Great for at home use and so easy to use!</td>\n      <td>This is perfect for my between salon visits. I...</td>\n      <td>[]</td>\n      <td>B08P2DZB4X</td>\n      <td>B08P2DZB4X</td>\n      <td>AFSKPY37N3C43SOI5IEXEK5JSIYA</td>\n      <td>1.627390e+12</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>5</td>\n      <td>Nice shampoo for the money</td>\n      <td>I get Keratin treatments at the salon at least...</td>\n      <td>[]</td>\n      <td>B086QY6T7N</td>\n      <td>B086QY6T7N</td>\n      <td>AFSKPY37N3C43SOI5IEXEK5JSIYA</td>\n      <td>1.626610e+12</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>3</td>\n      <td>Not what I thought I would be getting</td>\n      <td>I was very disappointed when I got this facial...</td>\n      <td>[]</td>\n      <td>B08DHTJ25J</td>\n      <td>B08DHTJ25J</td>\n      <td>AFSKPY37N3C43SOI5IEXEK5JSIYA</td>\n      <td>1.626210e+12</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>5</td>\n      <td>A little goes a long way!</td>\n      <td>This is a really nice moisturizing lotion. It ...</td>\n      <td>[]</td>\n      <td>B07RBSLNFR</td>\n      <td>B07RBSLNFR</td>\n      <td>AFSKPY37N3C43SOI5IEXEK5JSIYA</td>\n      <td>1.621180e+12</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>3</td>\n      <td>Just ok</td>\n      <td>I try to get Keratin treatments every 3 months...</td>\n      <td>[]</td>\n      <td>B07SLFWZKN</td>\n      <td>B07SLFWZKN</td>\n      <td>AFSKPY37N3C43SOI5IEXEK5JSIYA</td>\n      <td>1.619740e+12</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>695780</th>\n      <td>1</td>\n      <td>Product works-ish, very lazy packing.</td>\n      <td>Kinda mad that i picked this poly gel set bc i...</td>\n      <td>[]</td>\n      <td>B07PX9J8YJ</td>\n      <td>B07PX9J8YJ</td>\n      <td>AEUGNUJOAKJNWDHART2SX6VBTJ6A</td>\n      <td>1.608740e+12</td>\n      <td>False</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>695781</th>\n      <td>1</td>\n      <td>Product works-ish, very lazy packing.</td>\n      <td>Kinda mad that i picked this poly gel set bc i...</td>\n      <td>[]</td>\n      <td>B07PX9J8YJ</td>\n      <td>B07PX9J8YJ</td>\n      <td>AEUGNUJOAKJNWDHART2SX6VBTJ6A</td>\n      <td>1.608740e+12</td>\n      <td>False</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>695783</th>\n      <td>1</td>\n      <td>Product works-ish, very lazy packing.</td>\n      <td>Kinda mad that i picked this poly gel set bc i...</td>\n      <td>[]</td>\n      <td>B07PX9J8YJ</td>\n      <td>B07PX9J8YJ</td>\n      <td>AEUGNUJOAKJNWDHART2SX6VBTJ6A</td>\n      <td>1.608740e+12</td>\n      <td>False</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>695785</th>\n      <td>1</td>\n      <td>Product works-ish, very lazy packing.</td>\n      <td>Kinda mad that i picked this poly gel set bc i...</td>\n      <td>[]</td>\n      <td>B07PX9J8YJ</td>\n      <td>B07PX9J8YJ</td>\n      <td>AEUGNUJOAKJNWDHART2SX6VBTJ6A</td>\n      <td>1.608740e+12</td>\n      <td>False</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>695786</th>\n      <td>1</td>\n      <td>Product works-ish, very lazy packing.</td>\n      <td>Kinda mad that i picked this poly gel set bc i...</td>\n      <td>[]</td>\n      <td>B07PX9J8YJ</td>\n      <td>B07PX9J8YJ</td>\n      <td>AEUGNUJOAKJNWDHART2SX6VBTJ6A</td>\n      <td>1.608740e+12</td>\n      <td>False</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>14984 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_ratings"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-16T12:29:55.641194Z",
     "end_time": "2024-08-16T12:29:55.688692Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the datasets\n",
    "ratings = pd.read_csv('processed_dataset/Amazon-Beauty/amazon_beauty_ratings.csv')\n",
    "products = pd.read_csv('processed_dataset/Amazon-Beauty/amazon_beauty_reviews_meta.csv')\n",
    "\n",
    "# Convert ratings: 3, 4, 5 -> 1 and 1, 2 -> 0\n",
    "ratings['rating'] = ratings['rating'].apply(lambda x: 1 if x in [3, 4, 5] else 0)\n",
    "\n",
    "# Remove users with less than 10 interactions\n",
    "user_interactions = ratings['user_id'].value_counts()\n",
    "users_to_keep = user_interactions[user_interactions >= 10].index\n",
    "filtered_ratings = ratings[ratings['user_id'].isin(users_to_keep)]\n",
    "\n",
    "# Group data by user_id\n",
    "grouped = filtered_ratings.groupby('user_id')\n",
    "\n",
    "# Prepare containers for splits\n",
    "train_list = []\n",
    "val_list = []\n",
    "test_list = []\n",
    "\n",
    "# Define the sizes for validation and test sets\n",
    "val_size = 0.1\n",
    "test_size = 0.1\n",
    "\n",
    "# Process each user's ratings\n",
    "for userId, group in grouped:\n",
    "    # If there are not enough samples, assign all to training set\n",
    "    if len(group) < 3:\n",
    "        train_list.append(group.sort_values(by='timestamp'))\n",
    "        continue\n",
    "\n",
    "    # Split the data for each userId\n",
    "    train_data, temp_data = train_test_split(\n",
    "        group,\n",
    "        test_size=(val_size + test_size),\n",
    "        random_state=42,\n",
    "        shuffle=False  # Preserve timestamp order\n",
    "    )\n",
    "\n",
    "    if len(temp_data) < 2:  # If the temp_data is too small to split, add it all to the train set\n",
    "        train_list.append(train_data.sort_values(by='timestamp'))\n",
    "        continue\n",
    "\n",
    "    val_data, test_data = train_test_split(\n",
    "        temp_data,\n",
    "        test_size=test_size / (val_size + test_size),\n",
    "        random_state=42,\n",
    "        shuffle=False  # Preserve timestamp order\n",
    "    )\n",
    "\n",
    "    # Append sorted data\n",
    "    train_list.append(train_data.sort_values(by='timestamp'))\n",
    "    val_list.append(val_data.sort_values(by='timestamp'))\n",
    "    test_list.append(test_data.sort_values(by='timestamp'))\n",
    "\n",
    "# Concatenate all user-wise splits into final datasets\n",
    "train_set = pd.concat(train_list)\n",
    "val_set = pd.concat(val_list)\n",
    "test_set = pd.concat(test_list)\n",
    "\n",
    "# Save the datasets to CSV files\n",
    "train_set.to_csv('amazon_beauty_ratings_train.csv', index=False)\n",
    "val_set.to_csv('amazon_beauty_ratings_val.csv', index=False)\n",
    "test_set.to_csv('amazon_beauty_ratings_test.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-16T13:03:38.475495Z",
     "end_time": "2024-08-16T13:03:48.041536Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "        rating                                              title  \\\n368296       1                                    Love the Turban   \n368295       1                              No more chapped lips!   \n368294       1              Mess Contained in a Nifty Storage Box   \n368293       1                               Beauty Pageant Curls   \n368292       1                  Great Quality for a Cheaper Price   \n...        ...                                                ...   \n89191        1      Bamboo pin brush, comb, fluff brush.  SEE PIX   \n89189        0            Metal is garbage.  Not worth the price.   \n89188        1  Non-stick surface, accurate temp, LONG cord, i...   \n89187        1   Beachy waves on straight hair? Yes please! *pix*   \n89186        0  Sheer, MATTE and pale color unless you put on ...   \n\n                                                     text  \\\n368296  I'm such a lazy beauty enthusiast. I soak in t...   \n368295  Moisturizing and flavorful at the same time! I...   \n368294  This is one of the best gifts you could get fo...   \n368293  I was a bit nervous to use this at first becau...   \n368292  At the price of $20 (at the time of review), t...   \n...                                                   ...   \n89191   I have 2 standard poodles and their hair needs...   \n89189   I don't often leave a one star review but here...   \n89188   Love this multi-head curling iron.  My daughte...   \n89187   My daughter's hair is poker straight, thick an...   \n89186   Not sure what this formula is supposed to be. ...   \n\n                                                   images        asin  \\\n368296  [{'small_image_url': 'https://images-na.ssl-im...  B0841WQNNZ   \n368295  [{'small_image_url': 'https://images-na.ssl-im...  B08G5YVHQP   \n368294                                                 []  B08GS19PM7   \n368293  [{'small_image_url': 'https://images-na.ssl-im...  B08LPC1G23   \n368292                                                 []  B08NTD1NM1   \n...                                                   ...         ...   \n89191   [{'small_image_url': 'https://images-na.ssl-im...  B071YDJ269   \n89189                                                  []  B079FHCDGZ   \n89188   [{'small_image_url': 'https://images-na.ssl-im...  B08CXYYBHQ   \n89187   [{'small_image_url': 'https://images-na.ssl-im...  B08W2534W3   \n89186   [{'small_image_url': 'https://m.media-amazon.c...  B092YN4DG4   \n\n       parent_asin                       user_id     timestamp  \\\n368296  B0841WQNNZ  AE23ZBUF2YVBQPH2NN6F5XSA3QYQ  1.604550e+12   \n368295  B08G5YVHQP  AE23ZBUF2YVBQPH2NN6F5XSA3QYQ  1.605150e+12   \n368294  B08GS19PM7  AE23ZBUF2YVBQPH2NN6F5XSA3QYQ  1.607730e+12   \n368293  B08LPC1G23  AE23ZBUF2YVBQPH2NN6F5XSA3QYQ  1.608390e+12   \n368292  B08NTD1NM1  AE23ZBUF2YVBQPH2NN6F5XSA3QYQ  1.612040e+12   \n...            ...                           ...           ...   \n89191   B071YDJ269  AHYUFOFTGNEV4TGMQLASS6EA7QAQ  1.504330e+12   \n89189   B079FHCDGZ  AHYUFOFTGNEV4TGMQLASS6EA7QAQ  1.524510e+12   \n89188   B08CXYYBHQ  AHYUFOFTGNEV4TGMQLASS6EA7QAQ  1.600660e+12   \n89187   B08W2534W3  AHYUFOFTGNEV4TGMQLASS6EA7QAQ  1.622630e+12   \n89186   B092YN4DG4  AHYUFOFTGNEV4TGMQLASS6EA7QAQ  1.654790e+12   \n\n        verified_purchase  helpful_vote  \n368296              False             0  \n368295              False             0  \n368294              False             0  \n368293              False             0  \n368292              False             0  \n...                   ...           ...  \n89191               False            14  \n89189               False             0  \n89188                True             9  \n89187                True             1  \n89186               False             4  \n\n[5583 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rating</th>\n      <th>title</th>\n      <th>text</th>\n      <th>images</th>\n      <th>asin</th>\n      <th>parent_asin</th>\n      <th>user_id</th>\n      <th>timestamp</th>\n      <th>verified_purchase</th>\n      <th>helpful_vote</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>368296</th>\n      <td>1</td>\n      <td>Love the Turban</td>\n      <td>I'm such a lazy beauty enthusiast. I soak in t...</td>\n      <td>[{'small_image_url': 'https://images-na.ssl-im...</td>\n      <td>B0841WQNNZ</td>\n      <td>B0841WQNNZ</td>\n      <td>AE23ZBUF2YVBQPH2NN6F5XSA3QYQ</td>\n      <td>1.604550e+12</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>368295</th>\n      <td>1</td>\n      <td>No more chapped lips!</td>\n      <td>Moisturizing and flavorful at the same time! I...</td>\n      <td>[{'small_image_url': 'https://images-na.ssl-im...</td>\n      <td>B08G5YVHQP</td>\n      <td>B08G5YVHQP</td>\n      <td>AE23ZBUF2YVBQPH2NN6F5XSA3QYQ</td>\n      <td>1.605150e+12</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>368294</th>\n      <td>1</td>\n      <td>Mess Contained in a Nifty Storage Box</td>\n      <td>This is one of the best gifts you could get fo...</td>\n      <td>[]</td>\n      <td>B08GS19PM7</td>\n      <td>B08GS19PM7</td>\n      <td>AE23ZBUF2YVBQPH2NN6F5XSA3QYQ</td>\n      <td>1.607730e+12</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>368293</th>\n      <td>1</td>\n      <td>Beauty Pageant Curls</td>\n      <td>I was a bit nervous to use this at first becau...</td>\n      <td>[{'small_image_url': 'https://images-na.ssl-im...</td>\n      <td>B08LPC1G23</td>\n      <td>B08LPC1G23</td>\n      <td>AE23ZBUF2YVBQPH2NN6F5XSA3QYQ</td>\n      <td>1.608390e+12</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>368292</th>\n      <td>1</td>\n      <td>Great Quality for a Cheaper Price</td>\n      <td>At the price of $20 (at the time of review), t...</td>\n      <td>[]</td>\n      <td>B08NTD1NM1</td>\n      <td>B08NTD1NM1</td>\n      <td>AE23ZBUF2YVBQPH2NN6F5XSA3QYQ</td>\n      <td>1.612040e+12</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>89191</th>\n      <td>1</td>\n      <td>Bamboo pin brush, comb, fluff brush.  SEE PIX</td>\n      <td>I have 2 standard poodles and their hair needs...</td>\n      <td>[{'small_image_url': 'https://images-na.ssl-im...</td>\n      <td>B071YDJ269</td>\n      <td>B071YDJ269</td>\n      <td>AHYUFOFTGNEV4TGMQLASS6EA7QAQ</td>\n      <td>1.504330e+12</td>\n      <td>False</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>89189</th>\n      <td>0</td>\n      <td>Metal is garbage.  Not worth the price.</td>\n      <td>I don't often leave a one star review but here...</td>\n      <td>[]</td>\n      <td>B079FHCDGZ</td>\n      <td>B079FHCDGZ</td>\n      <td>AHYUFOFTGNEV4TGMQLASS6EA7QAQ</td>\n      <td>1.524510e+12</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>89188</th>\n      <td>1</td>\n      <td>Non-stick surface, accurate temp, LONG cord, i...</td>\n      <td>Love this multi-head curling iron.  My daughte...</td>\n      <td>[{'small_image_url': 'https://images-na.ssl-im...</td>\n      <td>B08CXYYBHQ</td>\n      <td>B08CXYYBHQ</td>\n      <td>AHYUFOFTGNEV4TGMQLASS6EA7QAQ</td>\n      <td>1.600660e+12</td>\n      <td>True</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>89187</th>\n      <td>1</td>\n      <td>Beachy waves on straight hair? Yes please! *pix*</td>\n      <td>My daughter's hair is poker straight, thick an...</td>\n      <td>[{'small_image_url': 'https://images-na.ssl-im...</td>\n      <td>B08W2534W3</td>\n      <td>B08W2534W3</td>\n      <td>AHYUFOFTGNEV4TGMQLASS6EA7QAQ</td>\n      <td>1.622630e+12</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>89186</th>\n      <td>0</td>\n      <td>Sheer, MATTE and pale color unless you put on ...</td>\n      <td>Not sure what this formula is supposed to be. ...</td>\n      <td>[{'small_image_url': 'https://m.media-amazon.c...</td>\n      <td>B092YN4DG4</td>\n      <td>B092YN4DG4</td>\n      <td>AHYUFOFTGNEV4TGMQLASS6EA7QAQ</td>\n      <td>1.654790e+12</td>\n      <td>False</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>5583 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-16T13:03:52.614157Z",
     "end_time": "2024-08-16T13:03:52.639154Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-16T22:36:39.805692Z",
     "end_time": "2024-08-16T22:36:41.104442Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "      user_id  gender       age              occupation zip_code\n0           1  Female  Under 18            K-12 student    48067\n1           2    Male       56+           self-employed    70072\n2           3    Male     25-34               scientist    55117\n3           4    Male     45-49    executive/managerial    02460\n4           5    Male     25-34                  writer    55455\n...       ...     ...       ...                     ...      ...\n6035     6036  Female     25-34               scientist    32603\n6036     6037  Female     45-49       academic/educator    76006\n6037     6038  Female       56+       academic/educator    14706\n6038     6039  Female     45-49  other or not specified    01060\n6039     6040    Male     25-34      doctor/health care    11106\n\n[6040 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>gender</th>\n      <th>age</th>\n      <th>occupation</th>\n      <th>zip_code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Female</td>\n      <td>Under 18</td>\n      <td>K-12 student</td>\n      <td>48067</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Male</td>\n      <td>56+</td>\n      <td>self-employed</td>\n      <td>70072</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Male</td>\n      <td>25-34</td>\n      <td>scientist</td>\n      <td>55117</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Male</td>\n      <td>45-49</td>\n      <td>executive/managerial</td>\n      <td>02460</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Male</td>\n      <td>25-34</td>\n      <td>writer</td>\n      <td>55455</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6035</th>\n      <td>6036</td>\n      <td>Female</td>\n      <td>25-34</td>\n      <td>scientist</td>\n      <td>32603</td>\n    </tr>\n    <tr>\n      <th>6036</th>\n      <td>6037</td>\n      <td>Female</td>\n      <td>45-49</td>\n      <td>academic/educator</td>\n      <td>76006</td>\n    </tr>\n    <tr>\n      <th>6037</th>\n      <td>6038</td>\n      <td>Female</td>\n      <td>56+</td>\n      <td>academic/educator</td>\n      <td>14706</td>\n    </tr>\n    <tr>\n      <th>6038</th>\n      <td>6039</td>\n      <td>Female</td>\n      <td>45-49</td>\n      <td>other or not specified</td>\n      <td>01060</td>\n    </tr>\n    <tr>\n      <th>6039</th>\n      <td>6040</td>\n      <td>Male</td>\n      <td>25-34</td>\n      <td>doctor/health care</td>\n      <td>11106</td>\n    </tr>\n  </tbody>\n</table>\n<p>6040 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = pd.read_csv('processed_dataset/MovieLens-1M/users/users_movielens_modified.csv')\n",
    "age_mapping = {\n",
    "    \"Under 18\": \"Teenager\",\n",
    "    \"18-24\": \"Young Adult\",\n",
    "    \"25-34\": \"Adult\",\n",
    "    \"35-44\": \"Middle-Aged Adult\",\n",
    "    \"45-49\": \"Older Adult\",\n",
    "    \"50-55\": \"Senior Adult\",\n",
    "    \"56+\": \"Elder\"\n",
    "}\n",
    "\n",
    "# Apply the mapping to the age column\n",
    "users['age'] = users['age'].map(age_mapping)\n",
    "\n",
    "users"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-17T11:00:28.740553Z",
     "end_time": "2024-08-17T11:00:28.817814Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "      item_id                        title                        genres  \\\n0           1                    Toy Story   Animation|Children's|Comedy   \n1           2                      Jumanji  Adventure|Children's|Fantasy   \n2           3             Grumpier Old Men                Comedy|Romance   \n3           4            Waiting to Exhale                  Comedy|Drama   \n4           5  Father of the Bride Part II                        Comedy   \n...       ...                          ...                           ...   \n3878     3948             Meet the Parents                        Comedy   \n3879     3949          Requiem for a Dream                         Drama   \n3880     3950                    Tigerland                         Drama   \n3881     3951             Two Family House                         Drama   \n3882     3952                    Contender                Drama|Thriller   \n\n     decade  \n0     1990s  \n1     1990s  \n2     1990s  \n3     1990s  \n4     1990s  \n...     ...  \n3878  2000s  \n3879  2000s  \n3880  2000s  \n3881  2000s  \n3882  2000s  \n\n[3883 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>item_id</th>\n      <th>title</th>\n      <th>genres</th>\n      <th>decade</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Toy Story</td>\n      <td>Animation|Children's|Comedy</td>\n      <td>1990s</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Jumanji</td>\n      <td>Adventure|Children's|Fantasy</td>\n      <td>1990s</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Grumpier Old Men</td>\n      <td>Comedy|Romance</td>\n      <td>1990s</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Waiting to Exhale</td>\n      <td>Comedy|Drama</td>\n      <td>1990s</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Father of the Bride Part II</td>\n      <td>Comedy</td>\n      <td>1990s</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3878</th>\n      <td>3948</td>\n      <td>Meet the Parents</td>\n      <td>Comedy</td>\n      <td>2000s</td>\n    </tr>\n    <tr>\n      <th>3879</th>\n      <td>3949</td>\n      <td>Requiem for a Dream</td>\n      <td>Drama</td>\n      <td>2000s</td>\n    </tr>\n    <tr>\n      <th>3880</th>\n      <td>3950</td>\n      <td>Tigerland</td>\n      <td>Drama</td>\n      <td>2000s</td>\n    </tr>\n    <tr>\n      <th>3881</th>\n      <td>3951</td>\n      <td>Two Family House</td>\n      <td>Drama</td>\n      <td>2000s</td>\n    </tr>\n    <tr>\n      <th>3882</th>\n      <td>3952</td>\n      <td>Contender</td>\n      <td>Drama|Thriller</td>\n      <td>2000s</td>\n    </tr>\n  </tbody>\n</table>\n<p>3883 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the dataset\n",
    "movies = pd.read_csv('processed_dataset/MovieLens-1M/movies/movies_movielens.csv')\n",
    "\n",
    "# Function to extract the year and create the decade string\n",
    "def extract_decade(title):\n",
    "    match = re.search(r'\\((\\d{4})\\)', title)\n",
    "    if match:\n",
    "        year = int(match.group(1))\n",
    "        decade = f\"{(year // 10) * 10}s\"\n",
    "        # Remove the year from the title\n",
    "        title = re.sub(r'\\(\\d{4}\\)', '', title).strip()\n",
    "        return title, decade\n",
    "    return title, \"Unknown\"\n",
    "\n",
    "# Function to clean up titles\n",
    "def clean_title(title):\n",
    "    # Remove ', The', ', A', or ', An' and adjust the title\n",
    "    title = re.sub(r',\\s(The|A|An)$', '', title).strip()\n",
    "    # Remove all commas from the title\n",
    "    title = title.replace(',', '')\n",
    "    return title\n",
    "\n",
    "# Function to process the title by cleaning and extracting the decade\n",
    "def process_title(title):\n",
    "    # Extract the decade and clean the title\n",
    "    title, decade_text = extract_decade(title)\n",
    "    # Further clean the title\n",
    "    title = clean_title(title)\n",
    "    return title, decade_text\n",
    "\n",
    "# Apply the function to the dataset\n",
    "movies[['title', 'decade']] = movies['title'].apply(lambda x: pd.Series(process_title(x)))\n",
    "\n",
    "# Save the modified dataset (if needed)\n",
    "# movies.to_csv('processed_dataset/MovieLens-1M/movies/movies_movielens_modified.csv', index=False)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "movies"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-17T10:18:53.324240Z",
     "end_time": "2024-08-17T10:18:53.944911Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   item_id                        title                        genres  \\\n",
      "0        1                    Toy Story   Animation|Children's|Comedy   \n",
      "1        2                      Jumanji  Adventure|Children's|Fantasy   \n",
      "2        3             Grumpier Old Men                Comedy|Romance   \n",
      "3        4            Waiting to Exhale                  Comedy|Drama   \n",
      "4        5  Father of the Bride Part II                        Comedy   \n",
      "\n",
      "     decade  \n",
      "0  Nineties  \n",
      "1  Nineties  \n",
      "2  Nineties  \n",
      "3  Nineties  \n",
      "4  Nineties  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the dataset\n",
    "movies = pd.read_csv('processed_dataset/MovieLens-1M/movies/movies_movielens.csv')\n",
    "\n",
    "# Function to convert the year to descriptive text\n",
    "def year_to_decade_text(year):\n",
    "    if 2000 <= year < 2010:\n",
    "        return \"Two Thousands\"\n",
    "    elif 1990 <= year < 2000:\n",
    "        return \"Nineties\"\n",
    "    elif 1980 <= year < 1990:\n",
    "        return \"Eighties\"\n",
    "    elif 1970 <= year < 1980:\n",
    "        return \"Seventies\"\n",
    "    elif 1960 <= year < 1970:\n",
    "        return \"Sixties\"\n",
    "    elif 1950 <= year < 1960:\n",
    "        return \"Fifties\"\n",
    "    elif 1940 <= year < 1950:\n",
    "        return \"Forties\"\n",
    "    elif 1930 <= year < 1940:\n",
    "        return \"Thirties\"\n",
    "    elif 1920 <= year < 1930:\n",
    "        return \"Twenties\"\n",
    "    else:\n",
    "        return \"Older\"\n",
    "\n",
    "# Function to extract the year, convert it to text, and remove it from the title\n",
    "def extract_decade_text(title):\n",
    "    match = re.search(r'\\((\\d{4})\\)', title)\n",
    "    if match:\n",
    "        year = int(match.group(1))\n",
    "        decade_text = year_to_decade_text(year)\n",
    "        # Remove the year from the title\n",
    "        title = re.sub(r'\\(\\d{4}\\)', '', title).strip()\n",
    "        return title, decade_text\n",
    "    return title, \"Unknown\"\n",
    "\n",
    "# Apply the function to the dataset\n",
    "movies[['title', 'decade']] = movies['title'].apply(lambda x: pd.Series(extract_decade_text(x)))\n",
    "\n",
    "# Save the modified dataset (if needed)\n",
    "# movies.to_csv('processed_dataset/MovieLens-1M/movies/movies_movielens_modified.csv', index=False)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(movies.head())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-16T22:41:23.894357Z",
     "end_time": "2024-08-16T22:41:24.462864Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "users.to_csv('users_movielens.csv', index=False)\n",
    "movies.to_csv('movies_movielens_modified2.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-08-17T11:00:38.713801Z",
     "end_time": "2024-08-17T11:00:38.749168Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
