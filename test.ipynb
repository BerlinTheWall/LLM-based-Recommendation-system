{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "import pandas as pd\n",
    "import random\n",
    "# train_ratings = pd.read_csv('processed_dataset/MovieLens-1M/ratings/traindata_movielens.csv')\n",
    "\n",
    "# Select 100 random samples\n",
    "# train_ratings = train_ratings.sample(n=10, random_state=42)\n",
    "ratings = torch.tensor([float(random.randint(1, 5)) for _ in range(5)])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-12T08:03:57.331012Z",
     "end_time": "2024-07-12T08:03:57.374816Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "titles = [\"Inception\", \"Titanic\", \"Avatar\", \"The Matrix\", \"The Godfather\", \"Star Wars\", \"The Dark Knight\", \"Pulp Fiction\", \"Forrest Gump\", \"Jurassic Park\"]\n",
    "genres = [\"Action\", \"Drama\", \"Sci-Fi\", \"Romance\", \"Thriller\", \"Comedy\", \"Adventure\", \"Fantasy\", \"Horror\", \"Mystery\"]\n",
    "years = [\"1994\", \"1999\", \"2008\", \"2010\", \"2014\", \"2018\", \"2020\", \"1984\", \"1995\", \"2001\"]\n",
    "\n",
    "movies = []\n",
    "for _ in range(5):\n",
    "    movie = random.choice(titles)\n",
    "    genre = random.choice(genres)\n",
    "    year = random.choice(years)\n",
    "    sample = f\"title: {movie} [SEP] genre: {genre} [SEP] year: {year}\"\n",
    "    movies.append(sample)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-12T08:03:58.804673Z",
     "end_time": "2024-07-12T08:03:58.851558Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "occupations = [\"doctor\", \"engineer\", \"teacher\", \"nurse\", \"writer\", \"musician\", \"artist\", \"lawyer\", \"scientist\", \"pilot\"]\n",
    "ages = [\"18-24\", \"25-34\", \"35-44\", \"45-54\", \"55-64\", \"65-74\", \"75+\"]\n",
    "genders = [\"Male\", \"Female\"]\n",
    "\n",
    "# Generate 10 random samples\n",
    "users = []\n",
    "for _ in range(5):\n",
    "    occupation = random.choice(occupations)\n",
    "    age = random.choice(ages)\n",
    "    gender = random.choice(genders)\n",
    "    sample = f\"profession: {occupation} [SEP] age range: {age} [SEP] gender: {gender}\"\n",
    "    users.append(sample)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-11T17:58:28.300521Z",
     "end_time": "2024-07-11T17:58:28.309026Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [
    {
     "data": {
      "text/plain": "'NVIDIA GeForce RTX 3060 Laptop GPU'"
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# torch.cuda.get_device_name(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-11T19:21:40.602369Z",
     "end_time": "2024-07-11T19:21:40.622370Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "users = [\n",
    "    \"profession: teacher [SEP] age range: 65-74\",\n",
    "    \"profession: musician [SEP] age range: 75+\",\n",
    "    \"profession: teacher [SEP] age range: 25-55\",\n",
    "    \"profession: musician [SEP] age range: 65-74\",\n",
    "    \"profession: teacher [SEP] age range: 45-55\",\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-12T08:04:00.804396Z",
     "end_time": "2024-07-12T08:04:00.866893Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "users = pd.read_csv('processed_dataset/MovieLens-1M/users/users_movielens.csv')\n",
    "movies = pd.read_csv('processed_dataset/MovieLens-1M/movies/movies_movielens.csv')\n",
    "train_ratings = pd.read_csv('processed_dataset/MovieLens-1M/ratings/traindata_movielens.csv')\n",
    "val_ratings = pd.read_csv('processed_dataset/MovieLens-1M/ratings/valdata_movielens.csv')\n",
    "test_ratings = pd.read_csv('processed_dataset/MovieLens-1M/ratings/testdata_movielens.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-12T08:26:28.205193Z",
     "end_time": "2024-07-12T08:26:28.479040Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# Combine user features into a single string for each user\n",
    "users['user_features'] = 'occupation: ' + users['occupation'] + ' [SEP] age: ' + users['age'].astype(str) + ' [SEP] gender: ' + users['gender'].astype(str)\n",
    "\n",
    "# Combine movie features into a single string for each movie\n",
    "movies['movie_features'] = 'title: ' + movies['title'] + ' [SEP] genres: ' + movies['genres']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-12T08:26:30.327917Z",
     "end_time": "2024-07-12T08:26:30.347105Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# Create a dictionary for fast lookup\n",
    "user_features_dict = users.set_index('user_id')['user_features'].to_dict()\n",
    "movie_features_dict = movies.set_index('item_id')['movie_features'].to_dict()\n",
    "\n",
    "# Create lists of user and item texts\n",
    "train_user_texts = [user_features_dict[userId] for userId in train_ratings['user_id']]\n",
    "train_item_texts = [movie_features_dict[movieId] for movieId in train_ratings['item_id'].unique()]\n",
    "\n",
    "# Create lists of user and item texts\n",
    "val_user_texts = [user_features_dict[userId] for userId in val_ratings['user_id']]\n",
    "val_item_texts = [movie_features_dict[movieId] for movieId in val_ratings['item_id'].unique()]\n",
    "\n",
    "train_item_id_to_idx = {movieId: idx for idx, movieId in enumerate(train_ratings['item_id'].unique())}\n",
    "val_item_id_to_idx = {movieId: idx for idx, movieId in enumerate(val_ratings['item_id'].unique())}\n",
    "test_item_id_to_idx = {movieId: idx for idx, movieId in enumerate(test_ratings['item_id'].unique())}\n",
    "\n",
    "test_item_texts = [movie_features_dict[movieId] for movieId in test_ratings['item_id'].unique()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-12T08:26:33.556747Z",
     "end_time": "2024-07-12T08:26:33.631358Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "'title: Silence of the Lambs, The (1991) [SEP] genres: Drama|Thriller'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_item_texts[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-11T22:18:26.763101Z",
     "end_time": "2024-07-11T22:18:26.789272Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "outputs": [
    {
     "data": {
      "text/plain": "'title: Stranger, The (1994) [SEP] genres: Action'"
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_features_dict[1434]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-11T22:10:27.909487Z",
     "end_time": "2024-07-11T22:10:27.926004Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "outputs": [
    {
     "data": {
      "text/plain": "3883"
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_features_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-11T22:03:52.549508Z",
     "end_time": "2024-07-11T22:03:52.564519Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "outputs": [
    {
     "data": {
      "text/plain": "3706"
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(item_texts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-11T22:04:54.564526Z",
     "end_time": "2024-07-11T22:04:54.590757Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "outputs": [
    {
     "data": {
      "text/plain": "200042"
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_user_texts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-11T21:27:07.006609Z",
     "end_time": "2024-07-11T21:27:07.030546Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "        user_id  item_id  rating   timestamp\n0          6040      858       4   956703932\n1          6040     3111       5   956704056\n2          6040      213       5   956704056\n3          6040      608       4   956704475\n4          6040     1649       5   956704519\n...         ...      ...     ...         ...\n200037     4958     2453       4  1046454260\n200038     4958     2043       1  1046454282\n200039     4958     2399       1  1046454338\n200040     4958     2634       3  1046454548\n200041     4958     1924       4  1046454590\n\n[200042 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6040</td>\n      <td>858</td>\n      <td>4</td>\n      <td>956703932</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6040</td>\n      <td>3111</td>\n      <td>5</td>\n      <td>956704056</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6040</td>\n      <td>213</td>\n      <td>5</td>\n      <td>956704056</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6040</td>\n      <td>608</td>\n      <td>4</td>\n      <td>956704475</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6040</td>\n      <td>1649</td>\n      <td>5</td>\n      <td>956704519</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>200037</th>\n      <td>4958</td>\n      <td>2453</td>\n      <td>4</td>\n      <td>1046454260</td>\n    </tr>\n    <tr>\n      <th>200038</th>\n      <td>4958</td>\n      <td>2043</td>\n      <td>1</td>\n      <td>1046454282</td>\n    </tr>\n    <tr>\n      <th>200039</th>\n      <td>4958</td>\n      <td>2399</td>\n      <td>1</td>\n      <td>1046454338</td>\n    </tr>\n    <tr>\n      <th>200040</th>\n      <td>4958</td>\n      <td>2634</td>\n      <td>3</td>\n      <td>1046454548</td>\n    </tr>\n    <tr>\n      <th>200041</th>\n      <td>4958</td>\n      <td>1924</td>\n      <td>4</td>\n      <td>1046454590</td>\n    </tr>\n  </tbody>\n</table>\n<p>200042 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ratings"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-12T08:30:06.679580Z",
     "end_time": "2024-07-12T08:30:06.710845Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "'occupation: doctor/health care [SEP] age: 25-34 [SEP] gender: Male'"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_user_texts[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-12T08:30:22.867656Z",
     "end_time": "2024-07-12T08:30:22.883302Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "'title: Godfather, The (1972) [SEP] genres: Action|Crime|Drama'"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_item_texts[item_id_to_idx.get(train_ratings['item_id'][0])]\n",
    "item_id = 858\n",
    "text = val_item_texts[val_item_id_to_idx[item_id]] if item_id in val_item_id_to_idx else \"Item ID not found\"\n",
    "text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-12T08:32:09.107586Z",
     "end_time": "2024-07-12T08:32:09.139276Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "{858: 0,\n 3111: 1,\n 213: 2,\n 608: 3,\n 1649: 4,\n 246: 5,\n 866: 6,\n 448: 7,\n 2324: 8,\n 58: 9,\n 1834: 10,\n 2391: 11,\n 2067: 12,\n 3022: 13,\n 1269: 14,\n 2804: 15,\n 2791: 16,\n 1197: 17,\n 935: 18,\n 3363: 19,\n 1265: 20,\n 3396: 21,\n 3471: 22,\n 924: 23,\n 1097: 24,\n 919: 25,\n 2565: 26,\n 1282: 27,\n 899: 28,\n 1947: 29,\n 364: 30,\n 588: 31,\n 2946: 32,\n 1380: 33,\n 1083: 34,\n 1212: 35,\n 923: 36,\n 920: 37,\n 232: 38,\n 1223: 39,\n 1221: 40,\n 1250: 41,\n 908: 42,\n 1299: 43,\n 1207: 44,\n 3469: 45,\n 1721: 46,\n 3468: 47,\n 1945: 48,\n 3359: 49,\n 1231: 50,\n 1949: 51,\n 2683: 52,\n 2707: 53,\n 2826: 54,\n 1203: 55,\n 3504: 56,\n 1276: 57,\n 2555: 58,\n 3285: 59,\n 2710: 60,\n 2975: 61,\n 2289: 62,\n 2038: 63,\n 3016: 64,\n 1293: 65,\n 2722: 66,\n 2546: 67,\n 1911: 68,\n 2575: 69,\n 926: 70,\n 2303: 71,\n 785: 72,\n 1953: 73,\n 235: 74,\n 968: 75,\n 2723: 76,\n 3325: 77,\n 2502: 78,\n 1956: 79,\n 2560: 80,\n 2396: 81,\n 2762: 82,\n 2840: 83,\n 2491: 84,\n 2702: 85,\n 2693: 86,\n 1623: 87,\n 50: 88,\n 1198: 89,\n 3149: 90,\n 1148: 91,\n 1267: 92,\n 3006: 93,\n 902: 94,\n 951: 95,\n 1247: 96,\n 2609: 97,\n 111: 98,\n 2628: 99,\n 3424: 100,\n 1080: 101,\n 1228: 102,\n 1584: 103,\n 589: 104,\n 480: 105,\n 32: 106,\n 3365: 107,\n 1876: 108,\n 1527: 109,\n 1356: 110,\n 1419: 111,\n 971: 112,\n 3156: 113,\n 512: 114,\n 1217: 115,\n 1150: 116,\n 1320: 117,\n 1779: 118,\n 2053: 119,\n 1590: 120,\n 66: 121,\n 1270: 122,\n 1376: 123,\n 2140: 124,\n 2311: 125,\n 1253: 126,\n 2642: 127,\n 1278: 128,\n 3362: 129,\n 3361: 130,\n 3418: 131,\n 1258: 132,\n 2064: 133,\n 1957: 134,\n 265: 135,\n 3130: 136,\n 249: 137,\n 1280: 138,\n 373: 139,\n 1264: 140,\n 961: 141,\n 150: 142,\n 3342: 143,\n 11: 144,\n 805: 145,\n 3255: 146,\n 913: 147,\n 2726: 148,\n 541: 149,\n 1480: 150,\n 875: 151,\n 1260: 152,\n 1284: 153,\n 293: 154,\n 3053: 155,\n 940: 156,\n 2288: 157,\n 605: 158,\n 1027: 159,\n 457: 160,\n 1586: 161,\n 3152: 162,\n 25: 163,\n 455: 164,\n 2431: 165,\n 1340: 166,\n 2412: 167,\n 981: 168,\n 1: 169,\n 2208: 170,\n 2501: 171,\n 594: 172,\n 356: 173,\n 959: 174,\n 1954: 175,\n 2542: 176,\n 1641: 177,\n 1827: 178,\n 3018: 179,\n 649: 180,\n 17: 181,\n 2384: 182,\n 1777: 183,\n 236: 184,\n 830: 185,\n 1042: 186,\n 372: 187,\n 1944: 188,\n 1582: 189,\n 1367: 190,\n 344: 191,\n 1689: 192,\n 1193: 193,\n 2036: 194,\n 1453: 195,\n 2042: 196,\n 2699: 197,\n 2152: 198,\n 2605: 199,\n 2670: 200,\n 2329: 201,\n 2949: 202,\n 1222: 203,\n 1127: 204,\n 780: 205,\n 339: 206,\n 1012: 207,\n 1129: 208,\n 2700: 209,\n 2859: 210,\n 3094: 211,\n 1196: 212,\n 1394: 213,\n 3521: 214,\n 3039: 215,\n 1096: 216,\n 2987: 217,\n 1210: 218,\n 3070: 219,\n 2750: 220,\n 3422: 221,\n 2407: 222,\n 1220: 223,\n 2746: 224,\n 2745: 225,\n 2985: 226,\n 2003: 227,\n 2376: 228,\n 2111: 229,\n 3088: 230,\n 2456: 231,\n 1373: 232,\n 3549: 233,\n 2948: 234,\n 2471: 235,\n 1846: 236,\n 862: 237,\n 3224: 238,\n 1292: 239,\n 904: 240,\n 1297: 241,\n 3011: 242,\n 2357: 243,\n 628: 244,\n 2427: 245,\n 47: 246,\n 2890: 247,\n 367: 248,\n 2455: 249,\n 1961: 250,\n 2287: 251,\n 3108: 252,\n 3282: 253,\n 2874: 254,\n 3494: 255,\n 2951: 256,\n 428: 257,\n 1332: 258,\n 1357: 259,\n 1968: 260,\n 3501: 261,\n 3143: 262,\n 1208: 263,\n 3175: 264,\n 1215: 265,\n 2237: 266,\n 474: 267,\n 3167: 268,\n 281: 269,\n 454: 270,\n 2109: 271,\n 558: 272,\n 1206: 273,\n 3194: 274,\n 728: 275,\n 3157: 276,\n 2124: 277,\n 1077: 278,\n 3421: 279,\n 912: 280,\n 1199: 281,\n 2664: 282,\n 1240: 283,\n 2640: 284,\n 1653: 285,\n 2105: 286,\n 593: 287,\n 1676: 288,\n 2012: 289,\n 1371: 290,\n 247: 291,\n 1690: 292,\n 1391: 293,\n 3044: 294,\n 2716: 295,\n 1994: 296,\n 442: 297,\n 2034: 298,\n 1591: 299,\n 1343: 300,\n 1350: 301,\n 377: 302,\n 905: 303,\n 2517: 304,\n 2087: 305,\n 34: 306,\n 1073: 307,\n 2: 308,\n 1029: 309,\n 1304: 310,\n 837: 311,\n 1307: 312,\n 1294: 313,\n 2409: 314,\n 3524: 315,\n 3552: 316,\n 3543: 317,\n 3499: 318,\n 3591: 319,\n 3529: 320,\n 3546: 321,\n 2167: 322,\n 2402: 323,\n 170: 324,\n 1036: 325,\n 1573: 326,\n 1370: 327,\n 2533: 328,\n 2662: 329,\n 1374: 330,\n 2916: 331,\n 674: 332,\n 2028: 333,\n 1917: 334,\n 318: 335,\n 162: 336,\n 2908: 337,\n 610: 338,\n 1389: 339,\n 1995: 340,\n 1986: 341,\n 2122: 342,\n 1979: 343,\n 1407: 344,\n 2159: 345,\n 188: 346,\n 1339: 347,\n 2279: 348,\n 2898: 349,\n 1644: 350,\n 152: 351,\n 177: 352,\n 2801: 353,\n 1643: 354,\n 1680: 355,\n 708: 356,\n 3358: 357,\n 2297: 358,\n 852: 359,\n 468: 360,\n 353: 361,\n 222: 362,\n 266: 363,\n 691: 364,\n 289: 365,\n 207: 366,\n 224: 367,\n 3261: 368,\n 3436: 369,\n 1483: 370,\n 2763: 371,\n 2571: 372,\n 3527: 373,\n 2058: 374,\n 2528: 375,\n 2490: 376,\n 490: 377,\n 2687: 378,\n 1242: 379,\n 969: 380,\n 3107: 381,\n 1608: 382,\n 2990: 383,\n 2476: 384,\n 1687: 385,\n 479: 386,\n 3129: 387,\n 357: 388,\n 562: 389,\n 571: 390,\n 2114: 391,\n 2108: 392,\n 3412: 393,\n 44: 394,\n 2701: 395,\n 205: 396,\n 1004: 397,\n 1497: 398,\n 1061: 399,\n 502: 400,\n 546: 401,\n 1626: 402,\n 296: 403,\n 1089: 404,\n 2764: 405,\n 1598: 406,\n 3112: 407,\n 3518: 408,\n 1177: 409,\n 366: 410,\n 574: 411,\n 261: 412,\n 1135: 413,\n 2894: 414,\n 1271: 415,\n 340: 416,\n 471: 417,\n 2912: 418,\n 1405: 419,\n 2090: 420,\n 2231: 421,\n 3395: 422,\n 1049: 423,\n 231: 424,\n 1081: 425,\n 1459: 426,\n 2779: 427,\n 808: 428,\n 2262: 429,\n 450: 430,\n 3173: 431,\n 2625: 432,\n 488: 433,\n 2613: 434,\n 2725: 435,\n 1200: 436,\n 1375: 437,\n 2094: 438,\n 316: 439,\n 504: 440,\n 2531: 441,\n 327: 442,\n 2091: 443,\n 880: 444,\n 2150: 445,\n 3114: 446,\n 110: 447,\n 3360: 448,\n 1408: 449,\n 1183: 450,\n 2795: 451,\n 260: 452,\n 2366: 453,\n 349: 454,\n 2470: 455,\n 2355: 456,\n 2085: 457,\n 3210: 458,\n 1663: 459,\n 440: 460,\n 1999: 461,\n 918: 462,\n 1175: 463,\n 1396: 464,\n 1019: 465,\n 1069: 466,\n 3334: 467,\n 1562: 468,\n 3576: 469,\n 3308: 470,\n 381: 471,\n 3350: 472,\n 597: 473,\n 410: 474,\n 3005: 475,\n 2858: 476,\n 733: 477,\n 1372: 478,\n 2617: 479,\n 849: 480,\n 160: 481,\n 836: 482,\n 2645: 483,\n 3447: 484,\n 3461: 485,\n 1225: 486,\n 1093: 487,\n 2761: 488,\n 2734: 489,\n 954: 490,\n 1281: 491,\n 2906: 492,\n 198: 493,\n 2115: 494,\n 1552: 495,\n 485: 496,\n 173: 497,\n 3032: 498,\n 2808: 499,\n 60: 500,\n 2522: 501,\n 2611: 502,\n 2712: 503,\n 3467: 504,\n 1214: 505,\n 2019: 506,\n 1387: 507,\n 1610: 508,\n 1291: 509,\n 2993: 510,\n 1047: 511,\n 592: 512,\n 2001: 513,\n 2367: 514,\n 2735: 515,\n 466: 516,\n 1037: 517,\n 153: 518,\n 2253: 519,\n 1303: 520,\n 952: 521,\n 3479: 522,\n 2135: 523,\n 1246: 524,\n 2950: 525,\n 1032: 526,\n 3101: 527,\n 2096: 528,\n 2080: 529,\n 2268: 530,\n 2857: 531,\n 1230: 532,\n 750: 533,\n 1188: 534,\n 1285: 535,\n 1588: 536,\n 2968: 537,\n 1797: 538,\n 2953: 539,\n 910: 540,\n 2511: 541,\n 1213: 542,\n 2130: 543,\n 1711: 544,\n 3384: 545,\n 2937: 546,\n 1537: 547,\n 2996: 548,\n 1948: 549,\n 921: 550,\n 2390: 551,\n 1238: 552,\n 2174: 553,\n 45: 554,\n 1066: 555,\n 3526: 556,\n 1914: 557,\n 909: 558,\n 3099: 559,\n 1288: 560,\n 2352: 561,\n 2690: 562,\n 1078: 563,\n 3061: 564,\n 1747: 565,\n 1201: 566,\n 489: 567,\n 2959: 568,\n 342: 569,\n 2144: 570,\n 2704: 571,\n 345: 572,\n 937: 573,\n 3118: 574,\n 2046: 575,\n 2454: 576,\n 2947: 577,\n 2193: 578,\n 2353: 579,\n 2989: 580,\n 165: 581,\n 2002: 582,\n 141: 583,\n 3448: 584,\n 156: 585,\n 2770: 586,\n 3451: 587,\n 2145: 588,\n 3087: 589,\n 2870: 590,\n 500: 591,\n 2469: 592,\n 2780: 593,\n 2794: 594,\n 378: 595,\n 1457: 596,\n 3590: 597,\n 195: 598,\n 520: 599,\n 2375: 600,\n 2717: 601,\n 2918: 602,\n 2473: 603,\n 1625: 604,\n 595: 605,\n 1545: 606,\n 1784: 607,\n 36: 608,\n 2000: 609,\n 3198: 610,\n 1693: 611,\n 2269: 612,\n 786: 613,\n 1488: 614,\n 1479: 615,\n 2336: 616,\n 2713: 617,\n 2901: 618,\n 2598: 619,\n 2424: 620,\n 329: 621,\n 587: 622,\n 1629: 623,\n 1894: 624,\n 1801: 625,\n 237: 626,\n 3073: 627,\n 1261: 628,\n 1645: 629,\n 1327: 630,\n 1924: 631,\n 2377: 632,\n 2513: 633,\n 2338: 634,\n 2163: 635,\n 303: 636,\n 2344: 637,\n 1580: 638,\n 1275: 639,\n 2322: 640,\n 2370: 641,\n 2991: 642,\n 145: 643,\n 3441: 644,\n 70: 645,\n 379: 646,\n 2276: 647,\n 1704: 648,\n 661: 649,\n 3176: 650,\n 2006: 651,\n 539: 652,\n 2125: 653,\n 2581: 654,\n 1353: 655,\n 736: 656,\n 2554: 657,\n 2553: 658,\n 2747: 659,\n 2097: 660,\n 1342: 661,\n 2793: 662,\n 2655: 663,\n 1984: 664,\n 1094: 665,\n 745: 666,\n 1126: 667,\n 1967: 668,\n 380: 669,\n 2054: 670,\n 2021: 671,\n 1041: 672,\n 1678: 673,\n 1897: 674,\n 1682: 675,\n 3246: 676,\n 52: 677,\n 2194: 678,\n 2023: 679,\n 1674: 680,\n 2474: 681,\n 2577: 682,\n 2363: 683,\n 1095: 684,\n 10: 685,\n 208: 686,\n 1617: 687,\n 492: 688,\n 123: 689,\n 350: 690,\n 1760: 691,\n 3538: 692,\n 290: 693,\n 999: 694,\n 22: 695,\n 2986: 696,\n 1354: 697,\n 3203: 698,\n 1219: 699,\n 2160: 700,\n 662: 701,\n 2551: 702,\n 2841: 703,\n 185: 704,\n 1500: 705,\n 2321: 706,\n 368: 707,\n 2539: 708,\n 1020: 709,\n 3263: 710,\n 1008: 711,\n 2393: 712,\n 1252: 713,\n 746: 714,\n 1009: 715,\n 3438: 716,\n 1702: 717,\n 1345: 718,\n 2789: 719,\n 24: 720,\n 1235: 721,\n 2020: 722,\n 1234: 723,\n 2406: 724,\n 2100: 725,\n 39: 726,\n 3481: 727,\n 3256: 728,\n 1923: 729,\n 1517: 730,\n 2301: 731,\n 1732: 732,\n 2133: 733,\n 292: 734,\n 1544: 735,\n 1587: 736,\n 376: 737,\n 1513: 738,\n 2405: 739,\n 20: 740,\n 2411: 741,\n 2421: 742,\n 2815: 743,\n 3429: 744,\n 3225: 745,\n 3440: 746,\n 1556: 747,\n 527: 748,\n 1262: 749,\n 1296: 750,\n 2706: 751,\n 2961: 752,\n 3555: 753,\n 2671: 754,\n 3398: 755,\n 3588: 756,\n 3534: 757,\n 2015: 758,\n 1300: 759,\n 2973: 760,\n 1273: 761,\n 3072: 762,\n 3138: 763,\n 1124: 764,\n 2072: 765,\n 3102: 766,\n 2417: 767,\n 2372: 768,\n 1952: 769,\n 1035: 770,\n 1136: 771,\n 2819: 772,\n 3135: 773,\n 3551: 774,\n 2137: 775,\n 2346: 776,\n 2530: 777,\n 2535: 778,\n 3354: 779,\n 1243: 780,\n 3408: 781,\n 3238: 782,\n 3273: 783,\n 2729: 784,\n 3105: 785,\n 21: 786,\n 491: 787,\n 1515: 788,\n 1079: 789,\n 1719: 790,\n 159: 791,\n 1699: 792,\n 3068: 793,\n 1950: 794,\n 1254: 795,\n 3496: 796,\n 506: 797,\n 3366: 798,\n 3037: 799,\n 2313: 800,\n 2800: 801,\n 1856: 802,\n 1672: 803,\n 2395: 804,\n 963: 805,\n 272: 806,\n 1569: 807,\n 2414: 808,\n 144: 809,\n 19: 810,\n 1597: 811,\n 2506: 812,\n 1286: 813,\n 494: 814,\n 832: 815,\n 2399: 816,\n 3189: 817,\n 2170: 818,\n 2567: 819,\n 1485: 820,\n 362: 821,\n 1858: 822,\n 2013: 823,\n 1835: 824,\n 2676: 825,\n 2688: 826,\n 1727: 827,\n 2724: 828,\n 2805: 829,\n 5: 830,\n 3197: 831,\n 2180: 832,\n 533: 833,\n 445: 834,\n 788: 835,\n 2088: 836,\n 2335: 837,\n 1752: 838,\n 2052: 839,\n 1665: 840,\n 2408: 841,\n 1882: 842,\n 2720: 843,\n 2882: 844,\n 2748: 845,\n 2398: 846,\n 2566: 847,\n 3201: 848,\n 2739: 849,\n 973: 850,\n 1397: 851,\n 1172: 852,\n 515: 853,\n 531: 854,\n 3260: 855,\n 444: 856,\n 945: 857,\n 2529: 858,\n 2657: 859,\n 1287: 860,\n 2905: 861,\n 3134: 862,\n 3096: 863,\n 2512: 864,\n 668: 865,\n 2732: 866,\n 1333: 867,\n 2202: 868,\n 573: 869,\n 3076: 870,\n 1963: 871,\n 680: 872,\n 976: 873,\n 3304: 874,\n 2070: 875,\n 3267: 876,\n 2926: 877,\n 915: 878,\n 2183: 879,\n 1935: 880,\n 2184: 881,\n 801: 882,\n 2078: 883,\n 1190: 884,\n 1101: 885,\n 970: 886,\n 2403: 887,\n 2273: 888,\n 3330: 889,\n 3368: 890,\n 2648: 891,\n 3269: 892,\n 2641: 893,\n 748: 894,\n 720: 895,\n 1283: 896,\n 1927: 897,\n 3475: 898,\n 900: 899,\n 3035: 900,\n 590: 901,\n 1939: 902,\n 337: 903,\n 1344: 904,\n 933: 905,\n 2495: 906,\n 2922: 907,\n 3252: 908,\n 2018: 909,\n 1358: 910,\n 1932: 911,\n 1266: 912,\n 3060: 913,\n 497: 914,\n 1619: 915,\n 564: 916,\n 164: 917,\n 2580: 918,\n 1912: 919,\n 1034: 920,\n 3196: 921,\n 2132: 922,\n 800: 923,\n 1251: 924,\n 2966: 925,\n 41: 926,\n 1885: 927,\n 1940: 928,\n 1729: 929,\n 529: 930,\n 2248: 931,\n 475: 932,\n 1788: 933,\n 1624: 934,\n 322: 935,\n 1958: 936,\n 1268: 937,\n 161: 938,\n 2420: 939,\n 1442: 940,\n 94: 941,\n 2252: 942,\n 1620: 943,\n 1978: 944,\n 1717: 945,\n 2110: 946,\n 1422: 947,\n 2803: 948,\n 1499: 949,\n 648: 950,\n 1053: 951,\n 1186: 952,\n 953: 953,\n 621: 954,\n 944: 955,\n 501: 956,\n 1204: 957,\n 914: 958,\n 233: 959,\n 97: 960,\n 1025: 961,\n 1683: 962,\n 154: 963,\n 1302: 964,\n 1836: 965,\n 2503: 966,\n 3545: 967,\n 2871: 968,\n 1365: 969,\n 3015: 970,\n 2479: 971,\n 3298: 972,\n 580: 973,\n 35: 974,\n 1735: 975,\n 2541: 976,\n 802: 977,\n 2077: 978,\n 2093: 979,\n 2944: 980,\n 1233: 981,\n 2881: 982,\n 3071: 983,\n 3397: 984,\n 1090: 985,\n 223: 986,\n 2041: 987,\n 2759: 988,\n 1263: 989,\n 2106: 990,\n 2527: 991,\n 2112: 992,\n 1472: 993,\n 2956: 994,\n 3247: 995,\n 3462: 996,\n 1028: 997,\n 2065: 998,\n 521: 999,\n ...}"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_item_id_to_idx"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-12T08:32:07.820462Z",
     "end_time": "2024-07-12T08:32:07.851736Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3070\n"
     ]
    }
   ],
   "source": [
    "print(item_id_to_idx.get(1433))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-11T21:59:27.753728Z",
     "end_time": "2024-07-11T21:59:27.789619Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "outputs": [
    {
     "data": {
      "text/plain": "'title: Machine, The (1994) [SEP] genres: Comedy|Horror'"
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_item_texts[3070]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-11T21:59:52.780114Z",
     "end_time": "2024-07-11T21:59:52.803117Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "4"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ratings['rating'][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-12T08:32:15.974009Z",
     "end_time": "2024-07-12T08:32:15.989632Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "outputs": [
    {
     "data": {
      "text/plain": "[0,\n 1,\n 2,\n 3,\n 4,\n 5,\n 6,\n 7,\n 8,\n 9,\n 10,\n 11,\n 12,\n 13,\n 14,\n 15,\n 16,\n 17,\n 18,\n 19,\n 20,\n 21,\n 22,\n 23,\n 24,\n 25,\n 26,\n 27,\n 28,\n 29,\n 30,\n 31,\n 32,\n 33,\n 34,\n 35,\n 36,\n 37,\n 38,\n 39,\n 40,\n 41,\n 42,\n 43,\n 44,\n 45,\n 46,\n 47,\n 48,\n 49,\n 50,\n 51,\n 52,\n 53,\n 54,\n 55,\n 56,\n 57,\n 58,\n 59,\n 60,\n 61,\n 62,\n 63,\n 64,\n 65,\n 66,\n 67,\n 68,\n 69,\n 70,\n 71,\n 72,\n 73,\n 74,\n 75,\n 76,\n 77,\n 78,\n 79,\n 80,\n 81,\n 82,\n 83,\n 84,\n 85,\n 86,\n 87,\n 88,\n 89,\n 90,\n 91,\n 92,\n 93,\n 94,\n 95,\n 96,\n 97,\n 98,\n 99,\n 100,\n 101,\n 102,\n 103,\n 104,\n 105,\n 106,\n 107,\n 108,\n 109,\n 110,\n 111,\n 112,\n 113,\n 114,\n 115,\n 116,\n 117,\n 118,\n 119,\n 120,\n 121,\n 122,\n 123,\n 124,\n 125,\n 126,\n 127,\n 128,\n 129,\n 130,\n 131,\n 132,\n 133,\n 134,\n 135,\n 136,\n 137,\n 138,\n 139,\n 140,\n 141,\n 142,\n 143,\n 144,\n 145,\n 146,\n 147,\n 148,\n 149,\n 150,\n 151,\n 152,\n 153,\n 154,\n 155,\n 156,\n 157,\n 158,\n 159,\n 160,\n 161,\n 162,\n 163,\n 164,\n 165,\n 166,\n 167,\n 168,\n 169,\n 170,\n 171,\n 172,\n 173,\n 174,\n 175,\n 176,\n 177,\n 178,\n 179,\n 180,\n 181,\n 182,\n 183,\n 184,\n 185,\n 186,\n 187,\n 188,\n 189,\n 190,\n 191,\n 192,\n 193,\n 194,\n 195,\n 196,\n 197,\n 198,\n 199,\n 200,\n 201,\n 202,\n 203,\n 204,\n 205,\n 206,\n 207,\n 208,\n 209,\n 210,\n 211,\n 212,\n 213,\n 214,\n 215,\n 216,\n 217,\n 218,\n 219,\n 220,\n 221,\n 222,\n 223,\n 224,\n 225,\n 226,\n 227,\n 228,\n 229,\n 230,\n 231,\n 232,\n 233,\n 234,\n 235,\n 236,\n 237,\n 238,\n 239,\n 240,\n 241,\n 242,\n 243,\n 244,\n 245,\n 246,\n 247,\n 248,\n 249,\n 250,\n 251,\n 252,\n 253,\n 254,\n 255,\n 256,\n 257,\n 258,\n 259,\n 260,\n 261,\n 262,\n 263,\n 264,\n 265,\n 266,\n 267,\n 268,\n 269,\n 270,\n 271,\n 272,\n 273,\n 274,\n 275,\n 276,\n 277,\n 278,\n 279,\n 280,\n 281,\n 282,\n 283,\n 284,\n 285,\n 286,\n 287,\n 288,\n 289,\n 290,\n 291,\n 292,\n 293,\n 294,\n 295,\n 296,\n 297,\n 298,\n 299,\n 300,\n 301,\n 302,\n 303,\n 304,\n 305,\n 306,\n 307,\n 308,\n 309,\n 310,\n 311,\n 312,\n 313,\n 314,\n 315,\n 316,\n 317,\n 318,\n 319,\n 320,\n 321,\n 322,\n 323,\n 324,\n 325,\n 326,\n 327,\n 328,\n 329,\n 330,\n 331,\n 332,\n 333,\n 334,\n 335,\n 336,\n 337,\n 338,\n 339,\n 340,\n 341,\n 342,\n 343,\n 344,\n 345,\n 346,\n 347,\n 348,\n 349,\n 350,\n 351,\n 352,\n 353,\n 354,\n 355,\n 356,\n 357,\n 358,\n 359,\n 360,\n 361,\n 362,\n 363,\n 364,\n 365,\n 366,\n 367,\n 368,\n 369,\n 370,\n 371,\n 372,\n 373,\n 374,\n 375,\n 376,\n 377,\n 378,\n 379,\n 380,\n 381,\n 382,\n 383,\n 384,\n 385,\n 386,\n 387,\n 388,\n 389,\n 390,\n 391,\n 392,\n 393,\n 394,\n 395,\n 396,\n 397,\n 398,\n 399,\n 400,\n 401,\n 402,\n 403,\n 404,\n 405,\n 406,\n 407,\n 408,\n 409,\n 410,\n 411,\n 412,\n 413,\n 414,\n 415,\n 416,\n 417,\n 418,\n 419,\n 420,\n 421,\n 422,\n 423,\n 424,\n 425,\n 426,\n 427,\n 428,\n 429,\n 430,\n 431,\n 432,\n 433,\n 434,\n 435,\n 436,\n 437,\n 438,\n 439,\n 440,\n 441,\n 442,\n 443,\n 444,\n 445,\n 446,\n 447,\n 448,\n 449,\n 450,\n 451,\n 452,\n 453,\n 454,\n 455,\n 456,\n 457,\n 458,\n 459,\n 460,\n 461,\n 462,\n 463,\n 464,\n 465,\n 466,\n 467,\n 468,\n 469,\n 470,\n 471,\n 472,\n 473,\n 474,\n 475,\n 476,\n 477,\n 478,\n 479,\n 480,\n 481,\n 482,\n 483,\n 484,\n 485,\n 486,\n 487,\n 488,\n 489,\n 490,\n 491,\n 492,\n 493,\n 494,\n 495,\n 496,\n 497,\n 498,\n 499,\n 500,\n 501,\n 502,\n 503,\n 504,\n 505,\n 506,\n 507,\n 508,\n 509,\n 510,\n 511,\n 512,\n 513,\n 514,\n 515,\n 516,\n 517,\n 518,\n 519,\n 520,\n 521,\n 522,\n 523,\n 524,\n 525,\n 526,\n 527,\n 528,\n 529,\n 530,\n 531,\n 532,\n 533,\n 534,\n 535,\n 536,\n 537,\n 538,\n 539,\n 540,\n 541,\n 542,\n 543,\n 544,\n 545,\n 546,\n 547,\n 548,\n 549,\n 550,\n 551,\n 552,\n 553,\n 554,\n 555,\n 556,\n 557,\n 558,\n 559,\n 560,\n 561,\n 562,\n 563,\n 564,\n 565,\n 566,\n 567,\n 568,\n 569,\n 570,\n 571,\n 572,\n 573,\n 574,\n 575,\n 576,\n 577,\n 578,\n 579,\n 580,\n 581,\n 582,\n 583,\n 584,\n 585,\n 586,\n 587,\n 588,\n 589,\n 590,\n 591,\n 592,\n 593,\n 594,\n 595,\n 596,\n 597,\n 598,\n 599,\n 600,\n 601,\n 602,\n 603,\n 604,\n 605,\n 606,\n 607,\n 608,\n 609,\n 610,\n 611,\n 612,\n 613,\n 614,\n 615,\n 616,\n 617,\n 618,\n 619,\n 620,\n 621,\n 622,\n 623,\n 624,\n 625,\n 626,\n 627,\n 628,\n 629,\n 630,\n 631,\n 632,\n 633,\n 634,\n 635,\n 636,\n 637,\n 638,\n 639,\n 640,\n 641,\n 642,\n 643,\n 644,\n 645,\n 646,\n 647,\n 648,\n 649,\n 650,\n 651,\n 652,\n 653,\n 654,\n 655,\n 656,\n 657,\n 658,\n 659,\n 660,\n 661,\n 662,\n 663,\n 664,\n 665,\n 666,\n 667,\n 668,\n 669,\n 670,\n 671,\n 672,\n 673,\n 674,\n 675,\n 676,\n 677,\n 678,\n 679,\n 680,\n 681,\n 682,\n 683,\n 684,\n 685,\n 686,\n 687,\n 688,\n 689,\n 690,\n 691,\n 692,\n 693,\n 694,\n 695,\n 696,\n 697,\n 698,\n 699,\n 700,\n 701,\n 702,\n 703,\n 704,\n 705,\n 706,\n 707,\n 708,\n 709,\n 710,\n 711,\n 712,\n 713,\n 714,\n 715,\n 716,\n 717,\n 718,\n 719,\n 720,\n 721,\n 722,\n 723,\n 724,\n 725,\n 726,\n 727,\n 728,\n 729,\n 730,\n 731,\n 732,\n 733,\n 734,\n 735,\n 736,\n 737,\n 738,\n 739,\n 740,\n 741,\n 742,\n 743,\n 744,\n 745,\n 746,\n 747,\n 748,\n 749,\n 750,\n 751,\n 752,\n 753,\n 754,\n 755,\n 756,\n 757,\n 758,\n 759,\n 760,\n 761,\n 762,\n 763,\n 764,\n 765,\n 766,\n 767,\n 768,\n 769,\n 770,\n 771,\n 772,\n 773,\n 774,\n 775,\n 776,\n 777,\n 778,\n 779,\n 780,\n 781,\n 782,\n 783,\n 784,\n 785,\n 786,\n 787,\n 788,\n 789,\n 790,\n 791,\n 792,\n 793,\n 794,\n 795,\n 796,\n 797,\n 798,\n 799,\n 800,\n 801,\n 802,\n 803,\n 804,\n 805,\n 806,\n 807,\n 808,\n 809,\n 810,\n 811,\n 812,\n 813,\n 814,\n 815,\n 816,\n 817,\n 818,\n 819,\n 820,\n 821,\n 822,\n 823,\n 824,\n 825,\n 826,\n 827,\n 828,\n 829,\n 830,\n 831,\n 832,\n 833,\n 834,\n 835,\n 836,\n 837,\n 838,\n 839,\n 840,\n 841,\n 842,\n 843,\n 844,\n 845,\n 846,\n 847,\n 848,\n 849,\n 850,\n 851,\n 852,\n 853,\n 854,\n 855,\n 856,\n 857,\n 858,\n 859,\n 860,\n 861,\n 862,\n 863,\n 864,\n 865,\n 866,\n 867,\n 868,\n 869,\n 870,\n 871,\n 872,\n 873,\n 874,\n 875,\n 876,\n 877,\n 878,\n 879,\n 880,\n 881,\n 882,\n 883,\n 884,\n 885,\n 886,\n 887,\n 888,\n 889,\n 890,\n 891,\n 892,\n 893,\n 894,\n 895,\n 896,\n 897,\n 898,\n 899,\n 900,\n 901,\n 902,\n 903,\n 904,\n 905,\n 906,\n 907,\n 908,\n 909,\n 910,\n 911,\n 912,\n 913,\n 914,\n 915,\n 916,\n 917,\n 918,\n 919,\n 920,\n 921,\n 922,\n 923,\n 924,\n 925,\n 926,\n 927,\n 928,\n 929,\n 930,\n 931,\n 932,\n 933,\n 934,\n 935,\n 936,\n 937,\n 938,\n 939,\n 940,\n 941,\n 942,\n 943,\n 944,\n 945,\n 946,\n 947,\n 948,\n 949,\n 950,\n 951,\n 952,\n 953,\n 954,\n 955,\n 956,\n 957,\n 958,\n 959,\n 960,\n 961,\n 962,\n 963,\n 964,\n 965,\n 966,\n 967,\n 968,\n 969,\n 970,\n 971,\n 972,\n 973,\n 974,\n 975,\n 976,\n 977,\n 978,\n 979,\n 980,\n 981,\n 982,\n 983,\n 984,\n 985,\n 986,\n 987,\n 988,\n 989,\n 990,\n 991,\n 992,\n 993,\n 994,\n 995,\n 996,\n 997,\n 998,\n 999,\n ...]"
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values_list = list(item_id_to_idx.values())\n",
    "values_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-11T20:17:58.290221Z",
     "end_time": "2024-07-11T20:17:58.346917Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "outputs": [
    {
     "data": {
      "text/plain": "'title: Silence of the Lambs, The (1991) [SEP] genres: Drama|Thriller'"
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_texts[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-11T20:15:14.693288Z",
     "end_time": "2024-07-11T20:15:14.719511Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [
    {
     "data": {
      "text/plain": "600125"
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_texts)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-11T20:07:53.632910Z",
     "end_time": "2024-07-11T20:07:53.659455Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [],
   "source": [
    "# # Create a dictionary for fast lookup\n",
    "# user_features_dict = users.set_index('user_id')['user_features'].to_dict()\n",
    "# movie_features_dict = movies.set_index('item_id')['movie_features'].to_dict()\n",
    "#\n",
    "# # Create lists of user and item texts\n",
    "# user_texts = [user_features_dict[userId] for userId in train_ratings['user_id']]\n",
    "# item_texts = [movie_features_dict[movieId] for movieId in train_ratings['item_id'].unique()]\n",
    "#\n",
    "# # Create a mapping from userId and movieId to indices\n",
    "# user_id_to_idx = {userId: idx for idx, userId in enumerate(train_ratings['user_id'])}\n",
    "# movie_id_to_idx = {movieId: idx for idx, movieId in enumerate(train_ratings['item_id'].unique())}\n",
    "#\n",
    "# # Map userId and movieId in ratings_df to indices\n",
    "# train_ratings['user_idx'] = train_ratings['user_id'].map(user_id_to_idx)\n",
    "# train_ratings['movie_idx'] = train_ratings['item_id'].map(movie_id_to_idx)\n",
    "#\n",
    "# # Map userId and movieId in ratings_val to indices\n",
    "# val_ratings['user_idx'] = val_ratings['user_id'].map(user_id_to_idx)\n",
    "# val_ratings['movie_idx'] = val_ratings['item_id'].map(movie_id_to_idx)\n",
    "#\n",
    "# # Extract user indices, item indices, and ratings\n",
    "# train_user_indices = torch.LongTensor(train_ratings['user_idx'].values).to(device)\n",
    "# train_item_indices = torch.LongTensor(train_ratings['movie_idx'].values).to(device)\n",
    "# train_labels = torch.FloatTensor(train_ratings['rating'].values).to(device)\n",
    "#\n",
    "# # Extract user indices, item indices, and ratings for validation\n",
    "# val_user_indices = torch.LongTensor(val_ratings['user_idx'].values).to(device)\n",
    "# val_item_indices = torch.LongTensor(val_ratings['movie_idx'].values).to(device)\n",
    "# val_labels = torch.FloatTensor(val_ratings['rating'].values).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-11T20:05:38.726472Z",
     "end_time": "2024-07-11T20:05:39.043018Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [
    {
     "data": {
      "text/plain": "0       occupation: K-12 student [SEP] age: Under 18 [...\n1       occupation: self-employed [SEP] age: 56+ [SEP]...\n2       occupation: scientist [SEP] age: 25-34 [SEP] g...\n3       occupation: executive/managerial [SEP] age: 45...\n4       occupation: writer [SEP] age: 25-34 [SEP] gend...\n                              ...                        \n6035    occupation: scientist [SEP] age: 25-34 [SEP] g...\n6036    occupation: academic/educator [SEP] age: 45-49...\n6037    occupation: academic/educator [SEP] age: 56+ [...\n6038    occupation: other or not specified [SEP] age: ...\n6039    occupation: doctor/health care [SEP] age: 25-3...\nName: user_features, Length: 6040, dtype: object"
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users['user_features']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-11T19:21:58.895619Z",
     "end_time": "2024-07-11T19:21:58.907731Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [],
   "source": [
    "ratings = torch.tensor([2., 4., 1., 5., 1.])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-11T19:18:38.038161Z",
     "end_time": "2024-07-11T19:18:38.061159Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([2., 4., 1., 5., 1.])"
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-11T19:18:38.318309Z",
     "end_time": "2024-07-11T19:18:38.333188Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "\n",
    "class UserItemDataset(Dataset):\n",
    "    def __init__(self, users, items, ratings):\n",
    "        self.users = users\n",
    "        self.items = items\n",
    "        self.ratings = ratings\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'user': self.users[idx],\n",
    "            'item': self.items[idx],\n",
    "            'rating': self.ratings[idx]\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-12T08:04:07.359437Z",
     "end_time": "2024-07-12T08:04:07.391571Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "data_length = len(train_user_texts)\n",
    "random_indices = random.sample(range(data_length), 10)\n",
    "\n",
    "random_user_texts = [train_user_texts[i] for i in random_indices]\n",
    "random_item_ids = [train_ratings['item_id'][i] for i in random_indices]\n",
    "random_ratings = [train_ratings['rating'][i] for i in random_indices]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-12T08:42:41.594286Z",
     "end_time": "2024-07-12T08:42:41.609913Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "random_indices = random.sample(range(data_length), 10)\n",
    "\n",
    "val_random_user_texts = [train_user_texts[i] for i in random_indices]\n",
    "val_random_item_ids = [train_ratings['item_id'][i] for i in random_indices]\n",
    "val_random_ratings = [train_ratings['rating'][i] for i in random_indices]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-12T08:43:08.332089Z",
     "end_time": "2024-07-12T08:43:08.348027Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "[3052, 233, 3208, 52, 2858, 2985, 3755, 653, 921, 2291]"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_item_ids"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-12T08:43:22.257783Z",
     "end_time": "2024-07-12T08:43:22.273429Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "# dataset = UserItemDataset(users, movies, ratings)\n",
    "train_dataset = UserItemDataset(random_user_texts, random_item_ids, random_ratings)\n",
    "val_dataset = UserItemDataset(val_random_user_texts, val_random_item_ids, val_random_ratings)\n",
    "\n",
    "# train_dataset = UserItemDataset(train_user_texts[:10], train_ratings['item_id'], train_ratings['rating'][:10])\n",
    "# val_dataset = UserItemDataset(val_user_texts[:5], val_ratings['item_id'], val_ratings['rating'][:5])\n",
    "\n",
    "# dataset[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-12T08:43:25.506964Z",
     "end_time": "2024-07-12T08:43:25.522480Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "'occupation: doctor/health care [SEP] age: 25-34 [SEP] gender: Male'"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.users[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-12T08:32:42.420761Z",
     "end_time": "2024-07-12T08:32:42.452055Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "593"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.items[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-12T08:32:42.828902Z",
     "end_time": "2024-07-12T08:32:42.843438Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "5"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.ratings[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-12T08:32:43.806264Z",
     "end_time": "2024-07-12T08:32:43.837953Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type                | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | user_model | SentenceTransformer | 22.7 M | train\n",
      "1 | item_model | SentenceTransformer | 22.7 M | train\n",
      "2 | user_fc    | Linear              | 147 K  | train\n",
      "3 | item_fc    | Linear              | 147 K  | train\n",
      "4 | criterion  | MSELoss             | 0      | train\n",
      "-----------------------------------------------------------\n",
      "45.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "45.7 M    Total params\n",
      "182.888   Total estimated model params size (MB)\n",
      "D:\\Anaconda\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "D:\\Anaconda\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2378,  764], device='cuda:0')\n",
      "tensor([2294,  785], device='cuda:0')\n",
      "Epoch 1: Val Loss: 2.638620376586914\n",
      "tensor([2378,  764], device='cuda:0')\n",
      "tensor([2294,  785], device='cuda:0')\n",
      "tensor([2321, 1394], device='cuda:0')\n",
      "tensor([3752, 1269], device='cuda:0')\n",
      "tensor([1210, 2302], device='cuda:0')\n",
      "Epoch 1: Val Loss: 2.444434642791748\n",
      "Epoch 1: Train Loss: 0.2743901014328003\n",
      "tensor([2378,  764], device='cuda:0')\n",
      "tensor([2294,  785], device='cuda:0')\n",
      "tensor([2321, 1394], device='cuda:0')\n",
      "tensor([3752, 1269], device='cuda:0')\n",
      "tensor([1210, 2302], device='cuda:0')\n",
      "Epoch 2: Val Loss: 2.447988986968994\n",
      "Epoch 2: Train Loss: 0.22457553446292877\n",
      "tensor([2378,  764], device='cuda:0')\n",
      "tensor([2294,  785], device='cuda:0')\n",
      "tensor([2321, 1394], device='cuda:0')\n",
      "tensor([3752, 1269], device='cuda:0')\n",
      "tensor([1210, 2302], device='cuda:0')\n",
      "Epoch 3: Val Loss: 2.405057430267334\n",
      "Epoch 3: Train Loss: 0.16349312663078308\n",
      "tensor([2378,  764], device='cuda:0')\n",
      "tensor([2294,  785], device='cuda:0')\n",
      "tensor([2321, 1394], device='cuda:0')\n",
      "tensor([3752, 1269], device='cuda:0')\n",
      "tensor([1210, 2302], device='cuda:0')\n",
      "Epoch 4: Val Loss: 2.3464157581329346\n",
      "Epoch 4: Train Loss: 0.11080898344516754\n",
      "tensor([2378,  764], device='cuda:0')\n",
      "tensor([2294,  785], device='cuda:0')\n",
      "tensor([2321, 1394], device='cuda:0')\n",
      "tensor([3752, 1269], device='cuda:0')\n",
      "tensor([1210, 2302], device='cuda:0')\n",
      "Epoch 5: Val Loss: 2.2902801036834717\n",
      "Epoch 5: Train Loss: 0.0744146928191185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch losses:\n",
      "Epoch 1: Train Loss: 0.2743901014328003, Val Loss: 2.638620376586914\n",
      "Epoch 2: Train Loss: 0.22457553446292877, Val Loss: 2.444434642791748\n",
      "Epoch 3: Train Loss: 0.16349312663078308, Val Loss: 2.447988986968994\n",
      "Epoch 4: Train Loss: 0.11080898344516754, Val Loss: 2.405057430267334\n",
      "Epoch 5: Train Loss: 0.0744146928191185, Val Loss: 2.3464157581329346\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class TwoTowerModel(pl.LightningModule):\n",
    "    def __init__(self, user_model_name, item_model_name, embedding_size=384):\n",
    "        super(TwoTowerModel, self).__init__()\n",
    "        self.user_model = SentenceTransformer(user_model_name)\n",
    "        self.item_model = SentenceTransformer(item_model_name)\n",
    "\n",
    "        self.user_fc = nn.Linear(embedding_size, embedding_size)\n",
    "        self.item_fc = nn.Linear(embedding_size, embedding_size)\n",
    "\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.epoch_losses = {'train_loss': [], 'val_loss': []}\n",
    "\n",
    "    def forward(self, user_text, item_text, step):\n",
    "        if step == 'train':\n",
    "            item_text = [train_item_texts[train_item_id_to_idx.get(item_text)] for item_text in item_text.tolist()]\n",
    "        elif step == 'val':\n",
    "            item_text = [val_item_texts[val_item_id_to_idx.get(item_text)] for item_text in item_text.tolist()]\n",
    "        else:\n",
    "            item_text = [test_item_texts[test_item_id_to_idx.get(item_text)] for item_text in item_text.tolist()]\n",
    "\n",
    "        # print(user_text, item_text)\n",
    "        user_embedding = self.user_model.encode(user_text, convert_to_tensor=True)\n",
    "        item_embedding = self.item_model.encode(item_text, convert_to_tensor=True)\n",
    "\n",
    "        user_output = self.user_fc(user_embedding)\n",
    "        item_output = self.item_fc(item_embedding)\n",
    "        # Log embeddings\n",
    "        # self.user_emb = user_embedding\n",
    "        # self.item_emb = item_embedding\n",
    "        # print(\"User Embedding:\", user_embedding)\n",
    "        # print(\"Item Embedding:\", item_embedding)\n",
    "        # print(\"User Output:\", user_output.size())\n",
    "        # print(\"Item Output:\", item_output.size())\n",
    "        # Compute the dot product for each user-item pair in the batch\n",
    "        dot_product = torch.sum(user_output * item_output, dim=1)\n",
    "        # print(\"Dot Product:\", dot_product)\n",
    "\n",
    "        return dot_product\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        user_texts = batch['user']\n",
    "        item_texts = batch['item']\n",
    "        ratings = batch['rating'].float()\n",
    "\n",
    "        preds = self(user_texts, item_texts, 'train')\n",
    "        preds = 4 * torch.sigmoid(preds) + 1\n",
    "        # print(user_texts, item_texts, preds, ratings)\n",
    "        loss = self.criterion(preds, ratings)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        user_texts = batch['user']\n",
    "        item_texts = batch['item']\n",
    "        ratings = batch['rating'].float()\n",
    "        print(item_texts)\n",
    "        preds = self(user_texts, item_texts, 'val')\n",
    "        preds = 4 * torch.sigmoid(preds) + 1\n",
    "\n",
    "        loss = self.criterion(preds, ratings)\n",
    "        self.log('val_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=1e-5)\n",
    "\n",
    "class PrintLossesCallback(Callback):\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        train_loss = trainer.callback_metrics.get('train_loss')\n",
    "        if train_loss is not None:\n",
    "            pl_module.epoch_losses['train_loss'].append(train_loss.item())\n",
    "            print(f\"Epoch {trainer.current_epoch + 1}: Train Loss: {train_loss.item()}\")\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        val_loss = trainer.callback_metrics.get('val_loss')\n",
    "        if val_loss is not None:\n",
    "            pl_module.epoch_losses['val_loss'].append(val_loss.item())\n",
    "            print(f\"Epoch {trainer.current_epoch + 1}: Val Loss: {val_loss.item()}\")\n",
    "\n",
    "# Example usage\n",
    "# users = [\"I love action movies\", \"Comedy movies are my favorite\"]\n",
    "# items = [\"An action-packed thriller\", \"A hilarious comedy\"]\n",
    "# ratings = torch.tensor([5.0, 4.0])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=2, drop_last=True)  # For demonstration purposes, using the same data for validation\n",
    "\n",
    "model = TwoTowerModel(user_model_name='paraphrase-MiniLM-L6-v2', item_model_name='paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=5, log_every_n_steps=1, callbacks=[PrintLossesCallback()], enable_progress_bar=False)\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "# Print losses after training completes\n",
    "print(\"Epoch losses:\")\n",
    "for epoch in range(trainer.max_epochs):\n",
    "    train_loss = model.epoch_losses['train_loss'][epoch] if epoch < len(model.epoch_losses['train_loss']) else 'N/A'\n",
    "    val_loss = model.epoch_losses['val_loss'][epoch] if epoch < len(model.epoch_losses['val_loss']) else 'N/A'\n",
    "    print(f\"Epoch {epoch + 1}: Train Loss: {train_loss}, Val Loss: {val_loss}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-12T08:44:21.506448Z",
     "end_time": "2024-07-12T08:44:33.543546Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "{'train_loss': [1.1349900960922241,\n  1.1209874153137207,\n  1.1229170560836792,\n  1.1273095607757568,\n  1.1311087608337402,\n  1.1337617635726929,\n  1.1353812217712402,\n  1.1362100839614868,\n  1.1364727020263672,\n  1.1363470554351807],\n 'val_loss': [1.5670127868652344,\n  1.1985464096069336,\n  1.1731033325195312,\n  1.16090726852417,\n  1.1534429788589478,\n  1.1482261419296265,\n  1.144281268119812,\n  1.1411384344100952,\n  1.1385533809661865,\n  1.13637375831604,\n  1.1345018148422241]}"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.epoch_losses"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-12T01:47:42.551079Z",
     "end_time": "2024-07-12T01:47:42.573609Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "def get_top_n_recommendations(user_text, model, item_dataset, n=5):\n",
    "    item_texts = [item_dataset[i] for i in range(len(item_dataset))]\n",
    "    item_texts= torch.tensor(item_texts)\n",
    "    # print(item_texts)\n",
    "    preds = model.forward(user_text, item_texts, 'test')\n",
    "    preds = 4 * torch.sigmoid(preds) + 1\n",
    "    top_n_indices = torch.argsort(preds, descending=True)[:n]\n",
    "    top_n_items = [item_dataset[i] for i in top_n_indices]\n",
    "    top_n_scores = preds[top_n_indices]\n",
    "    return list(zip(top_n_items, top_n_scores))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-12T08:44:42.816406Z",
     "end_time": "2024-07-12T08:44:42.848148Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3052,  233, 3208,   52, 2858, 2985, 3755,  653,  921, 2291])\n"
     ]
    }
   ],
   "source": [
    "# Example user text\n",
    "# user_text = \"profession: doctor [SEP] age range: 65-74 [SEP] gender: Male\"\n",
    "user_text = \"profession: scientist [SEP] age range: 75+ [SEP] gender: Male\"\n",
    "\n",
    "top_recommendations = get_top_n_recommendations(user_text, model, random_item_ids, n=10)\n",
    "# top_recommendations = get_top_n_recommendations(user_text, model, movies, n=5)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-12T08:53:49.001661Z",
     "end_time": "2024-07-12T08:53:49.112893Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "['title: Dogma (1999) [SEP] genres: Comedy',\n 'title: Exotica (1994) [SEP] genres: Drama',\n 'title: Loaded Weapon 1 (1993) [SEP] genres: Action|Comedy',\n 'title: Mighty Aphrodite (1995) [SEP] genres: Comedy',\n 'title: American Beauty (1999) [SEP] genres: Comedy|Drama',\n 'title: Robocop (1987) [SEP] genres: Action|Crime|Sci-Fi',\n 'title: Perfect Storm, The (2000) [SEP] genres: Action|Adventure|Thriller',\n 'title: Dragonheart (1996) [SEP] genres: Action|Adventure|Fantasy',\n 'title: My Favorite Year (1982) [SEP] genres: Comedy',\n 'title: Edward Scissorhands (1990) [SEP] genres: Drama|Romance']"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_item_texts = [movie_features_dict[movieId] for movieId in random_item_ids]\n",
    "t_item_texts"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-12T08:47:39.070654Z",
     "end_time": "2024-07-12T08:47:39.086306Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "['3052 title: Dogma (1999) [SEP] genres: Comedy',\n '233 title: Exotica (1994) [SEP] genres: Drama',\n '3208 title: Loaded Weapon 1 (1993) [SEP] genres: Action|Comedy',\n '52 title: Mighty Aphrodite (1995) [SEP] genres: Comedy',\n '2858 title: American Beauty (1999) [SEP] genres: Comedy|Drama',\n '2985 title: Robocop (1987) [SEP] genres: Action|Crime|Sci-Fi',\n '3755 title: Perfect Storm, The (2000) [SEP] genres: Action|Adventure|Thriller',\n '653 title: Dragonheart (1996) [SEP] genres: Action|Adventure|Fantasy',\n '921 title: My Favorite Year (1982) [SEP] genres: Comedy',\n '2291 title: Edward Scissorhands (1990) [SEP] genres: Drama|Romance']"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f\"{item_id} {text}\" for item_id, text in zip(random_item_ids, t_item_texts)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-12T08:50:53.485090Z",
     "end_time": "2024-07-12T08:50:53.500735Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "# data = {\n",
    "#     \"User\": users,  # Repeating users to match the number of ratings\n",
    "#     \"Movie\": movies,\n",
    "#     \"Rating\": ratings\n",
    "# }\n",
    "data = {\n",
    "    \"User\": random_user_texts,  # Repeating users to match the number of ratings\n",
    "    \"Movie\": [f\"{item_id} {text}\" for item_id, text in zip(random_item_ids, t_item_texts)],\n",
    "    \"Rating\": random_ratings\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-12T08:51:03.422111Z",
     "end_time": "2024-07-12T08:51:03.437761Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-12T08:51:03.836006Z",
     "end_time": "2024-07-12T08:51:03.851630Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                User  \\\n0  occupation: unemployed [SEP] age: 18-24 [SEP] ...   \n1  occupation: writer [SEP] age: 45-49 [SEP] gend...   \n2  occupation: other or not specified [SEP] age: ...   \n3  occupation: technician/engineer [SEP] age: 18-...   \n4  occupation: scientist [SEP] age: 25-34 [SEP] g...   \n5  occupation: technician/engineer [SEP] age: 25-...   \n6  occupation: college/grad student [SEP] age: 18...   \n7  occupation: other or not specified [SEP] age: ...   \n8  occupation: scientist [SEP] age: 25-34 [SEP] g...   \n9  occupation: academic/educator [SEP] age: 25-34...   \n\n                                               Movie  Rating  \n0      3052 title: Dogma (1999) [SEP] genres: Comedy       3  \n1      233 title: Exotica (1994) [SEP] genres: Drama       2  \n2  3208 title: Loaded Weapon 1 (1993) [SEP] genre...       2  \n3  52 title: Mighty Aphrodite (1995) [SEP] genres...       1  \n4  2858 title: American Beauty (1999) [SEP] genre...       3  \n5  2985 title: Robocop (1987) [SEP] genres: Actio...       3  \n6  3755 title: Perfect Storm, The (2000) [SEP] ge...       1  \n7  653 title: Dragonheart (1996) [SEP] genres: Ac...       4  \n8  921 title: My Favorite Year (1982) [SEP] genre...       3  \n9  2291 title: Edward Scissorhands (1990) [SEP] g...       3  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User</th>\n      <th>Movie</th>\n      <th>Rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>occupation: unemployed [SEP] age: 18-24 [SEP] ...</td>\n      <td>3052 title: Dogma (1999) [SEP] genres: Comedy</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>occupation: writer [SEP] age: 45-49 [SEP] gend...</td>\n      <td>233 title: Exotica (1994) [SEP] genres: Drama</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>occupation: other or not specified [SEP] age: ...</td>\n      <td>3208 title: Loaded Weapon 1 (1993) [SEP] genre...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>occupation: technician/engineer [SEP] age: 18-...</td>\n      <td>52 title: Mighty Aphrodite (1995) [SEP] genres...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>occupation: scientist [SEP] age: 25-34 [SEP] g...</td>\n      <td>2858 title: American Beauty (1999) [SEP] genre...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>occupation: technician/engineer [SEP] age: 25-...</td>\n      <td>2985 title: Robocop (1987) [SEP] genres: Actio...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>occupation: college/grad student [SEP] age: 18...</td>\n      <td>3755 title: Perfect Storm, The (2000) [SEP] ge...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>occupation: other or not specified [SEP] age: ...</td>\n      <td>653 title: Dragonheart (1996) [SEP] genres: Ac...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>occupation: scientist [SEP] age: 25-34 [SEP] g...</td>\n      <td>921 title: My Favorite Year (1982) [SEP] genre...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>occupation: academic/educator [SEP] age: 25-34...</td>\n      <td>2291 title: Edward Scissorhands (1990) [SEP] g...</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-12T08:51:04.527305Z",
     "end_time": "2024-07-12T08:51:04.555692Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user_text = \"profession: scientist [SEP] age range: 75+ [SEP] gender: Male\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "[(921, tensor(2.9823, grad_fn=<UnbindBackward0>)),\n (653, tensor(2.7847, grad_fn=<UnbindBackward0>)),\n (3052, tensor(2.7314, grad_fn=<UnbindBackward0>)),\n (3208, tensor(2.3732, grad_fn=<UnbindBackward0>)),\n (2985, tensor(2.3191, grad_fn=<UnbindBackward0>)),\n (2858, tensor(2.2966, grad_fn=<UnbindBackward0>)),\n (3755, tensor(2.2466, grad_fn=<UnbindBackward0>)),\n (52, tensor(2.2301, grad_fn=<UnbindBackward0>)),\n (2291, tensor(2.1117, grad_fn=<UnbindBackward0>)),\n (233, tensor(1.7996, grad_fn=<UnbindBackward0>))]"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_recommendations"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-12T08:53:53.550374Z",
     "end_time": "2024-07-12T08:53:53.581641Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 8.3276e-01,  8.2051e-02,  3.0309e-01,  2.1005e-01, -3.0842e-01,\n          8.1448e-01, -9.2465e-02, -3.7289e-01,  8.7239e-02,  6.1374e-01,\n         -1.7548e-01, -2.6898e-01,  1.0095e-01,  2.0776e-02, -2.9030e-02,\n          3.1094e-01, -1.5206e-01, -1.8223e-01,  7.2254e-01,  2.6763e-01,\n         -1.7961e-01,  2.1395e-01,  2.5993e-01, -6.7496e-01,  5.0078e-01,\n         -6.1833e-01, -2.8589e-01,  1.1161e-01, -2.1280e-01, -2.1083e-01,\n          3.3463e-01,  4.1669e-01,  4.4386e-01, -1.3550e-02,  5.8307e-02,\n         -1.3067e-01, -1.0299e+00,  1.5860e-01, -2.2157e-02,  3.0831e-01,\n         -4.3915e-02, -7.7502e-02, -1.4880e-01, -6.4330e-01, -1.1070e-02,\n          1.3839e-01, -1.5811e-01, -4.4167e-04,  1.1641e-01,  3.9993e-01,\n         -9.0280e-01, -6.9036e-01,  1.4046e-01,  3.3495e-01, -3.1607e-01,\n         -4.2657e-01,  7.9768e-03,  2.0949e-02,  2.9584e-01,  6.0345e-02,\n         -2.0942e-01,  3.5031e-01, -7.5630e-01, -7.8596e-02,  1.1698e-02,\n          1.8370e-01,  2.7463e-01, -2.2647e-01, -5.1463e-01, -2.2512e-01,\n          7.8242e-01,  3.2106e-02, -7.7322e-01,  2.1582e-01, -2.1292e-01,\n         -2.5159e-01,  2.5032e-01, -2.8854e-01, -2.9649e-01, -5.1485e-01,\n         -1.4622e-01, -1.8560e-01,  5.5014e-01,  4.3860e-01, -5.3643e-02,\n         -1.4040e-01, -1.0401e-01,  5.1303e-01, -4.3075e-01,  2.8474e-02,\n         -7.3643e-01,  4.2515e-01,  9.4882e-02,  1.3320e-01,  4.3929e-01,\n         -1.0217e-01, -4.9056e-01,  2.9555e-02, -2.4031e-02,  1.9549e-01,\n         -3.5877e-01,  2.4292e-01, -6.0599e-01,  1.3100e-01, -1.9176e-01,\n          2.3639e-01,  3.6063e-02,  9.3734e-02, -6.1209e-01,  9.6297e-02,\n         -2.7773e-01, -3.3263e-01, -6.0056e-01, -8.8490e-02,  7.3837e-01,\n         -2.4242e-01, -3.1456e-02,  5.3593e-01,  6.0033e-01, -2.5884e-01,\n          2.1452e-02,  3.4959e-01, -3.4327e-01, -8.9604e-02, -7.7647e-01,\n         -1.6773e-02,  3.1348e-01,  4.6392e-01, -1.0160e-01, -2.2815e-01,\n          3.0520e-01,  5.1015e-01, -1.7305e-01,  2.9503e-01,  4.0743e-01,\n         -1.4123e-01, -8.1605e-02, -8.8577e-02,  5.1438e-01, -2.0590e-01,\n          4.3643e-02,  3.8097e-01,  1.1231e-01,  8.8909e-01,  7.8547e-01,\n         -2.6942e-01, -5.8359e-02,  1.8940e-01, -1.9058e-01, -2.8994e-03,\n         -2.7281e-02, -9.1563e-02, -1.0460e-01,  1.3294e-01,  3.1341e-01,\n         -3.1787e-01,  3.6173e-01,  1.6428e-01, -7.0287e-01,  2.8113e-01,\n          4.3499e-01, -3.8832e-01, -1.1706e-01, -7.4676e-01,  7.5036e-02,\n         -5.9869e-03,  4.9309e-01,  3.8180e-02,  2.0430e-01,  1.0100e-02,\n         -2.7976e-01, -5.6840e-02,  1.6210e-01,  5.9210e-01,  4.2477e-02,\n         -4.3092e-02, -5.1757e-01,  9.9156e-01, -3.9818e-01,  5.1095e-01,\n          7.0172e-02,  1.3745e-01, -6.8429e-02, -2.0156e-01,  1.0175e-01,\n         -9.5770e-02, -1.9969e-01, -1.8394e-01,  1.5755e-01,  6.6891e-01,\n          7.3555e-02, -9.3493e-03,  2.0358e-01,  1.6998e-01,  4.1351e-01,\n          1.0383e-01,  4.7893e-01,  1.3188e-01, -3.8274e-01, -4.0721e-02,\n         -1.5471e-01,  1.1400e-01,  2.9865e-01, -4.6097e-01,  1.9142e-01,\n         -4.1908e-01,  7.3672e-01,  7.6209e-01,  2.0649e-01,  9.7470e-01,\n         -4.0581e-01, -6.6050e-01, -3.1794e-01, -2.7418e-01,  1.5252e-01,\n         -3.4661e-01, -6.1580e-02,  2.4481e-01, -1.2935e-01,  3.4678e-01,\n         -4.1878e-01,  2.2551e-01, -2.0526e-01, -3.5731e-01,  8.0298e-02,\n         -3.7236e-01, -2.6381e-01,  5.5163e-01,  1.5273e-01, -1.1511e-01,\n          5.7473e-02,  3.1080e-01,  7.2497e-01,  2.8659e-01, -3.1237e-01,\n         -7.5698e-01,  1.7696e-01, -2.3001e-01, -3.4688e-01, -1.1398e-01,\n         -1.1247e-01,  2.4838e-01, -3.0356e-01, -6.6134e-02, -6.2495e-01,\n          7.7487e-01,  8.3242e-02,  2.8060e-02,  7.4994e-02,  3.6826e-01,\n         -1.6825e-01, -3.8060e-01,  6.4771e-02,  6.1730e-01, -2.5861e-01,\n         -5.0922e-01,  4.3064e-02, -2.4058e-01,  2.1639e-01,  1.0362e-01,\n         -1.4789e-01, -3.0424e-01,  1.6454e-01,  2.1495e-02,  6.5893e-02,\n          3.1358e-01,  1.1120e-01, -6.5640e-02, -5.3546e-01, -2.4717e-01,\n         -5.5412e-01,  2.1726e-01,  4.3570e-01, -3.0521e-02, -2.0005e-01,\n         -9.6223e-02,  1.6250e-01, -6.2729e-01, -1.2445e-01, -9.2624e-01,\n          5.4763e-02, -4.6641e-02, -4.5645e-01,  1.1164e+00,  1.8519e-01,\n          3.7379e-01, -1.0182e-01, -1.5513e-01, -9.5553e-02,  4.1599e-01,\n         -2.8443e-01,  4.5367e-01, -4.4578e-01,  1.9917e-01,  2.1698e-01,\n          2.4812e-01, -2.2679e-01,  5.1939e-01, -5.5082e-01, -4.3584e-03,\n          8.5715e-02,  2.9225e-01, -6.9190e-02, -4.6007e-01,  8.9400e-02,\n         -1.6486e-01, -1.0937e-01,  7.5504e-01, -4.9099e-01,  6.8818e-01,\n         -3.3294e-01, -4.7048e-01, -1.9973e-01, -1.2757e-01,  3.5124e-01,\n         -4.1181e-01,  1.1270e-02, -6.3155e-01, -2.6879e-01, -2.4380e-01,\n         -3.2979e-01, -3.0511e-03,  4.0776e-01, -3.6300e-02, -2.0751e-02,\n          8.4362e-01,  1.1595e-01, -3.3513e-01, -2.6797e-01,  3.6880e-01,\n          4.5429e-01, -3.3696e-01,  9.6582e-01,  2.2910e-01,  5.0438e-01,\n         -8.8814e-01,  1.3297e-01, -1.3468e-01, -3.0484e-02, -5.2739e-01,\n          8.9115e-01, -1.7289e-01,  2.4072e-02, -3.8473e-01, -4.8479e-01,\n          2.8879e-01,  4.7816e-01,  1.6866e-01, -9.9530e-01,  7.5668e-02,\n          7.7367e-01,  3.7261e-01, -2.3590e-01,  2.3689e-01,  3.3994e-01,\n         -7.7163e-01, -2.3755e-01,  7.1955e-02, -8.0450e-01, -3.2059e-02,\n         -3.4371e-01, -1.1443e-01,  1.9465e-03,  1.5047e-01, -1.9185e-01,\n         -2.1149e-01,  7.3609e-01, -1.1158e-01, -3.5945e-01,  4.8769e-01,\n          2.5681e-02, -1.5025e-01,  4.2485e-01, -4.3595e-01,  2.7902e-01,\n          3.9096e-02,  4.0814e-01,  5.6609e-01, -2.6718e-01,  1.0508e-01,\n          6.2215e-01, -5.7828e-01,  2.0234e-01, -8.7792e-02]], device='cuda:0')"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.user_emb"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-11T18:07:24.815637Z",
     "end_time": "2024-07-11T18:07:24.842815Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 3.8231e-02, -5.1786e-01,  2.8932e-01, -6.5171e-02, -2.2142e-01,\n          4.8638e-01, -3.7634e-01, -1.0395e-03,  5.1911e-02,  2.2404e-01,\n          1.9158e-01, -1.5225e-01, -6.5987e-01,  3.5734e-02,  1.8200e-01,\n         -1.5093e-01,  4.0238e-01,  6.6269e-02,  6.9296e-01,  5.6623e-01,\n          1.0681e-01,  6.3442e-01,  2.1215e-01, -6.2358e-01,  1.9043e-01,\n         -5.2030e-01,  1.6891e-01,  3.1781e-01, -6.8459e-01, -1.2312e-01,\n          4.7328e-01,  4.6238e-02, -2.1466e-01,  5.2682e-02,  1.6736e-01,\n          1.9360e-01,  3.4173e-01,  2.5968e-01,  2.0081e-01, -5.5312e-01,\n         -3.8487e-01,  2.2561e-01,  1.7053e-01,  3.6520e-01, -2.2282e-01,\n         -1.8844e-01, -3.3730e-01, -5.5030e-01,  5.9279e-01,  2.9978e-01,\n         -6.6722e-01, -1.8076e-01, -3.6294e-01,  1.3673e-01,  6.3215e-01,\n         -4.3464e-02,  1.1103e-01,  3.4903e-01,  9.4543e-02,  1.7410e-01,\n          2.7457e-01, -1.4252e-01, -6.0077e-01,  1.5249e-01,  1.1750e-01,\n         -4.0101e-01,  1.4326e-02,  4.5923e-01, -8.4205e-01, -3.7340e-01,\n         -4.1628e-01,  4.5180e-03,  1.3433e-01,  5.6374e-02, -2.7356e-01,\n          3.9423e-01, -2.9877e-01, -3.8818e-01,  2.9713e-02, -1.2057e-01,\n         -6.3025e-01, -5.4156e-01,  1.4398e-01,  3.8124e-01, -7.5380e-01,\n          4.2977e-01,  3.0990e-01, -1.5271e-01, -8.6344e-02,  1.5442e-01,\n         -4.6243e-01, -9.6447e-02,  6.0254e-01,  4.7526e-01, -1.6289e-01,\n         -1.5551e-02, -3.2029e-01, -2.1506e-01,  2.1102e-02,  4.2586e-02,\n          1.1702e-01,  2.3820e-01, -6.0345e-02,  2.3917e-01,  3.3010e-01,\n          1.1153e-01,  6.4926e-01, -1.8130e-01,  5.8967e-02, -1.7923e-01,\n          3.5043e-01, -2.0742e-01, -4.8906e-01,  1.6604e-02,  5.6745e-01,\n          1.3757e-01,  1.0394e+00,  3.0643e-01,  2.3883e-01,  2.0641e-01,\n          5.3822e-01,  1.2327e-01, -7.1077e-02, -4.2443e-01, -5.6200e-01,\n         -3.8013e-01,  6.0274e-01,  3.8033e-01, -2.4641e-01, -2.0923e-01,\n         -5.0137e-01,  8.1783e-02,  6.9849e-01, -1.1977e-02,  5.4133e-02,\n          1.4470e-01, -1.7552e-01,  2.7974e-01,  8.8503e-02, -3.5871e-01,\n         -8.6784e-01,  2.2219e-01, -6.4845e-02, -3.9419e-02, -6.0128e-02,\n         -1.7356e-02, -2.3588e-01,  1.6398e-02, -2.5199e-01,  4.7205e-01,\n         -1.4878e-01, -7.7610e-01, -5.2373e-01, -2.6065e-01, -1.2428e-01,\n         -3.6359e-01,  8.9093e-01,  5.8673e-01, -8.4065e-02, -7.0372e-02,\n          7.7801e-04, -1.4344e-01,  8.5949e-01, -2.7010e-01, -1.3503e-01,\n         -4.7475e-01, -2.9782e-01,  8.6426e-01, -4.5525e-01, -1.7364e-01,\n         -2.7060e-01, -5.1022e-02, -8.1845e-02,  5.7810e-02,  1.4830e-01,\n         -1.3807e-01, -1.7887e-01,  5.9623e-01, -1.3536e-01,  3.0430e-01,\n          1.2679e-01,  7.1920e-02, -9.1067e-03,  2.6793e-02, -4.2147e-01,\n         -2.8994e-01,  4.7886e-01, -6.8390e-03, -1.9431e-01,  2.8042e-02,\n          2.7028e-01, -4.8044e-01, -1.3446e-01,  3.3741e-01,  2.0614e-01,\n          3.3128e-01,  3.6128e-01,  5.0105e-01, -7.3331e-01,  1.1303e-01,\n         -7.0101e-01, -1.1270e-01,  3.6880e-01, -2.9147e-01,  1.7816e-01,\n          4.6104e-02, -1.5979e-01, -1.7853e-01, -2.6835e-01,  1.8438e-01,\n         -4.3252e-01, -6.3367e-01, -4.4822e-01, -1.1716e-02, -3.1209e-01,\n          3.0631e-02, -1.2843e-01, -3.0671e-01, -2.9471e-01,  1.9864e-01,\n          4.1769e-03, -2.8389e-01, -3.7208e-02, -2.7449e-01,  1.9914e-01,\n         -4.4625e-01, -9.9967e-01,  2.4033e-01,  1.5302e-02,  4.6949e-01,\n         -1.0126e+00,  8.3718e-02,  5.6701e-02, -1.5220e-01, -7.5342e-01,\n          3.3318e-02, -1.1364e-01,  1.8711e-01, -4.5541e-01, -5.8133e-01,\n         -1.1984e-01, -2.3070e-01, -2.9448e-01,  2.8450e-01, -3.4987e-01,\n         -1.2997e-01, -9.4675e-02,  3.7338e-01,  5.4534e-01,  2.8377e-01,\n         -1.1207e-01,  3.8179e-01,  6.8833e-02,  3.4970e-01,  4.3208e-01,\n          6.6735e-02,  2.4664e-01, -2.6974e-01,  2.1185e-01,  2.5070e-01,\n          4.2037e-01,  2.4759e-01, -2.0753e-01, -1.5697e-01,  2.5453e-01,\n         -2.2543e-01, -2.5248e-01,  9.5425e-02, -8.4175e-01,  3.3501e-01,\n          2.0453e-01, -1.5683e-01,  4.8368e-01, -4.9605e-02, -2.0916e-01,\n          3.4120e-02, -1.5543e-01, -7.6688e-01, -4.0461e-01, -9.9144e-02,\n         -2.2988e-01, -1.8344e-01, -1.6611e-01,  5.6293e-01, -7.0715e-01,\n          5.7039e-01,  1.6977e-01, -1.5302e-01,  4.6152e-01,  2.7423e-02,\n          4.4765e-02, -1.4283e-01, -9.4789e-01, -1.2054e-01, -2.5617e-01,\n          4.1187e-01, -9.4846e-01,  4.7585e-01, -8.7417e-06,  3.4390e-01,\n          9.7270e-02, -2.3770e-01, -1.4507e-01,  8.3693e-01,  2.9839e-01,\n          3.6977e-01, -3.7313e-01,  4.9806e-01,  4.0347e-02,  2.8724e-01,\n          2.0200e-01,  6.9189e-01, -1.6340e-01,  2.0485e-01,  7.0457e-01,\n          2.1638e-01,  2.6341e-01, -1.7488e-01, -2.8141e-01, -1.4340e-01,\n         -3.6041e-01,  7.3524e-02, -6.1323e-02, -1.2873e-01, -1.7689e-01,\n          7.5052e-01,  2.0512e-01, -4.2993e-01, -1.3940e-01,  4.6180e-01,\n          2.6538e-02,  8.7086e-02,  1.3642e-01,  2.2311e-01, -2.3391e-01,\n          3.3285e-01,  2.9247e-01, -2.3715e-01, -1.2384e-01, -2.2707e-01,\n          5.3009e-01,  1.1000e-01,  3.9003e-01, -3.4800e-01, -3.5627e-01,\n          3.0742e-01, -2.6155e-01, -6.0291e-01,  5.7436e-02,  5.1627e-01,\n          6.9414e-01,  6.1418e-01, -2.4356e-01,  3.2885e-01, -5.7513e-01,\n          2.2540e-02,  1.4865e-01,  1.9866e-01, -1.5267e-01,  9.9654e-02,\n          3.2580e-01,  1.9786e-01,  7.7659e-02,  1.5922e-01,  2.3381e-01,\n          3.9121e-01,  5.1478e-01, -5.9549e-01, -3.1673e-01,  2.8588e-01,\n          6.8506e-01, -2.5710e-01,  1.1996e-01,  4.6705e-01,  8.0530e-02,\n          2.5235e-03,  2.8927e-01,  6.4907e-01, -1.0434e+00,  3.4585e-02,\n          5.8671e-01, -7.8835e-01, -2.8696e-02, -9.6221e-02]], device='cuda:0')"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.item_emb"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-11T18:07:34.552949Z",
     "end_time": "2024-07-11T18:07:34.607159Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot product: 16.750228881835938\n"
     ]
    }
   ],
   "source": [
    "# Calculate the dot product\n",
    "dot_product = torch.sum(model.user_emb * model.item_emb, dim=1)\n",
    "\n",
    "print(\"Dot product:\", dot_product.item())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-11T18:09:32.890930Z",
     "end_time": "2024-07-11T18:09:32.901930Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot product: tensor([16.7502], device='cuda:0')\n",
      "User embedding magnitude: tensor([7.4314], device='cuda:0')\n",
      "Item embedding magnitude: tensor([7.2215], device='cuda:0')\n",
      "Theoretical max dot product: tensor([53.6660], device='cuda:0')\n",
      "Theoretical min dot product: tensor([-53.6660], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Calculate the dot product\n",
    "dot_product = torch.sum(model.user_emb *  model.item_emb, dim=1)\n",
    "\n",
    "# Calculate magnitudes\n",
    "user_magnitude = torch.norm(model.user_emb, dim=1)\n",
    "item_magnitude = torch.norm( model.item_emb, dim=1)\n",
    "\n",
    "# Theoretical maximum and minimum dot product values\n",
    "max_dot_product = user_magnitude * item_magnitude\n",
    "min_dot_product = -max_dot_product\n",
    "\n",
    "# Display results\n",
    "print(f\"Dot product: {dot_product}\")\n",
    "print(f\"User embedding magnitude: {user_magnitude}\")\n",
    "print(f\"Item embedding magnitude: {item_magnitude}\")\n",
    "print(f\"Theoretical max dot product: {max_dot_product}\")\n",
    "print(f\"Theoretical min dot product: {min_dot_product}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-07-11T18:11:37.368144Z",
     "end_time": "2024-07-11T18:11:37.438663Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
